\section{Model Evaluation}\label{section:evaluation}

\begin{frame}{Model Evaluation}
	\begin{itemize}
		\item \textbf{Classification models might perform differently depending on the use case.} \\
		      $\Rightarrow$ \textbf{\color{airforceblue}Model evaluation} is crucial to select the best model for a specific task.
		\item \textbf{Model evaluation can be split into two parts:}
		      \begin{itemize}
			      \item \textbf{\color{airforceblue}Evaluation metrics:} \\
			            What metric is important for the task?

			      \item \textbf{\color{airforceblue}Evaluation strategies:} \\
			            How to tackle the evaluation? E.g. how to split the data into training and test sets?
		      \end{itemize}
	\end{itemize}
\end{frame}

\subsection{Evaluation Metrics}

\begin{frame}{Confusion Matrix}

	\vspace*{-1em}

	\input{7-classification/confusion-matrix.tex}

	\begin{itemize}
		\item \textbf{Confusion Matrix:}
		      \begin{itemize}
			      \item Summarizes the results of a classification model.
			      \item Shows the number of correct and incorrect predictions for each class.
			      \item \textbf{\color{airforceblue}Correctly classified tuples:}
			            \begin{itemize}
				            \item \textbf{True Positives (TP)}: Positive tuples correctly classified as positive.
				            \item \textbf{True Negatives (TN)}: Negative tuples correctly classified as negative.
			            \end{itemize}
			      \item \textbf{\color{airforceblue}Incorrectly classified tuples:}
			            \begin{itemize}
				            \item \textbf{False Positives (FP)}: Negative tuples incorrectly classified as positive.
				            \item \textbf{False Negatives (FN)}: Positive tuples incorrectly classified as negative.
			            \end{itemize}
		      \end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}{Evaluation Metrics: Accuracy and Error Rate}

	\vspace*{-1em}

	\input{7-classification/confusion-matrix.tex}

	\rule{\textwidth}{0.4pt}

	\vspace*{-0.25cm}

	\begin{columns}
		\begin{column}{0.45\textwidth}
			\begin{itemize}

				\item \textbf{Accuracy:}
				      \visible<2->{
					      \begin{itemize}
						      \item Percentage of correctly classified tuples.
					      \end{itemize}
				      }
			\end{itemize}
		\end{column}
		\begin{column}{0.45\textwidth}

			\begin{itemize}

				\item \textbf{Error Rate:}
				      \visible<3->{
					      \begin{itemize}
						      \item Inverse of accuracy, i.e. percentage of incorrectly classified tuples.
					      \end{itemize}
				      }
			\end{itemize}

		\end{column}
	\end{columns}

	\vspace*{-0.1em}

	\begin{columns}
		\begin{column}{0.45\textwidth}
			\visible<2->{
				\begin{align*}
					\text{Accuracy} & = \frac{\text{TP} + \text{TN}}{\text{P} +  \text{N}} \\
				\end{align*}
			}
		\end{column}
		\begin{column}{0.45\textwidth}
			\visible<3->{
				\begin{align*}
					\text{Error Rate} & = 1 - \text{Accuracy}                               \\
					                  & = \frac{\text{FP} + \text{FN}}{\text{P} + \text{N}} \\
				\end{align*}
			}
		\end{column}
	\end{columns}

	\vspace*{-2em}
\end{frame}

\begin{frame}{Evaluation Metrics: Sensitivity and Specificity}

	\vspace*{-1em}

	\input{7-classification/confusion-matrix.tex}

	\rule{\textwidth}{0.4pt}

	\vspace*{-0.25cm}

	\begin{columns}
		\begin{column}{0.45\textwidth}

			\begin{itemize}

				\item \textbf{Sensitivity:}
				      \visible<2->{
					      \begin{itemize}
						      \item True positive rate.
					      \end{itemize}
				      }
			\end{itemize}

		\end{column}
		\begin{column}{0.45\textwidth}
			\begin{itemize}

				\item \textbf{Specificity:}
				      \visible<3->{
					      \begin{itemize}
						      \item True negative rate.
					      \end{itemize}
				      }
			\end{itemize}

		\end{column}
	\end{columns}

	\vspace*{-0.1em}

	\begin{columns}
		\begin{column}{0.45\textwidth}
			\visible<2->{
				\begin{align*}
					\text{Sensitivity} & = \frac{\text{TP}}{\text{P}} \\
				\end{align*}
			}
		\end{column}
		\begin{column}{0.45\textwidth}
			\visible<3->{
				\begin{align*}
					\text{Specificity} & = \frac{\text{TN}}{\text{N}} \\
				\end{align*}
			}
		\end{column}
	\end{columns}

	\vspace*{-2em}
\end{frame}

\begin{frame}{Evaluation Metrics: Precision and Recall}

	\vspace*{-1em}

	\input{7-classification/confusion-matrix.tex}

	\rule{\textwidth}{0.4pt}

	\vspace*{-0.25cm}

	\begin{columns}
		\begin{column}{0.45\textwidth}
			\begin{itemize}

				\item \textbf{Precision:}
				      \visible<2->{
					      \begin{itemize}
						      \item Measure of exactness.
					      \end{itemize}
				      }
			\end{itemize}
		\end{column}
		\begin{column}{0.45\textwidth}

			\begin{itemize}

				\item \textbf{Recall:}
				      \visible<3->{
					      \begin{itemize}
						      \item Measure of completeness.
					      \end{itemize}
				      }
			\end{itemize}

		\end{column}
	\end{columns}

	\vspace*{-0.1em}

	\begin{columns}
		\begin{column}{0.45\textwidth}
			\visible<2->{
				\begin{align*}
					\text{Precision} & = \frac{\text{TP}}{\text{TP} + \text{FP}} \\
				\end{align*}
			}
		\end{column}
		\begin{column}{0.45\textwidth}
			\visible<3->{
				\begin{align*}
					\text{Recall} & =  \frac{\text{TP}}{\text{TP} + \text{FN}}     \\
					\visible<4->{ & = \text{Sensitivity} \\}
				\end{align*}
			}
		\end{column}
	\end{columns}

	\vspace*{-2em}
\end{frame}

\begin{frame}{Evaluation Metrics: $\text{\textbf{F}}_\beta$ and $\text{\textbf{F}}_1$ Measure}

	\vspace*{-1em}

	\input{7-classification/confusion-matrix.tex}

	\rule{\textwidth}{0.4pt}

	\vspace*{-0.25cm}

	\begin{columns}
		\begin{column}{0.45\textwidth}

			\begin{itemize}
				\item \textbf{$\text{\textbf{F}}_\beta$ Measure:}
				      \visible<2->{
					      \begin{itemize}
						      \item Combining precision and recall.
						      \item Gives $\beta$-times more weight to precision.
						      \item $\beta > 1$: Minimize false positives.
						      \item $\beta < 1$: Minimize false negatives.
					      \end{itemize}
				      }
			\end{itemize}

		\end{column}
		\begin{column}{0.45\textwidth}

			\begin{itemize}
				\item \textbf{$\text{\textbf{F}}_1$ Measure:}
				      \visible<3->{
					      \begin{itemize}
						      \item Harmonic mean between the measures.
						      \item Equal weight to both measures.
					      \end{itemize}
				      }
			\end{itemize}

		\end{column}
	\end{columns}

	\vspace*{-0.1em}

	\begin{columns}
		\begin{column}{0.45\textwidth}
			\visible<2->{
				\begin{align*}
					\text{F}_\beta & = \frac{(1 + \beta^2) \times \text{Precision} \times \text{Recall}}{\beta^2 \times \text{Precision} + \text{Recall}}
				\end{align*}
			}
		\end{column}
		\begin{column}{0.45\textwidth}
			\visible<3->{
				\begin{align*}
					\text{F}_1 & = \frac{2 \times \text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}} \\
				\end{align*}
			}
		\end{column}
	\end{columns}

	\vspace*{-2em}
\end{frame}

\begin{frame}{Evaluation Metrics: Example (I)}
	\begin{itemize}
		\item \textbf{Evaluation results of a classification model:}
	\end{itemize}

	\vspace*{0.2cm}

	\begin{center}
		\begin{tabular}{|r|c|c|c|c|c|c|c|c|c|c|}
			\hline
			\cellcolor{faugray!62}\textit{True Class}      & \only<3>{\cellcolor{faugray!28}}Cat & \only<9>{\cellcolor{faugray!28}}Dog & \only<7>{\cellcolor{faugray!28}}Fox & \only<5>{\cellcolor{faugray!28}}Cat & \only<3>{\cellcolor{faugray!28}}Cat & \only<9>{\cellcolor{faugray!28}}Hen & \only<3>{\cellcolor{faugray!28}}Cat & \only<5>{\cellcolor{faugray!28}}Cat & \only<9>{\cellcolor{faugray!28}}Dog & \only<9>{\cellcolor{faugray!28}}Fox \\ \hline
			\cellcolor{faugray!62}\textit{Predicted Class} & \only<3>{\cellcolor{faugray!28}}Cat & \only<9>{\cellcolor{faugray!28}}Dog & \only<7>{\cellcolor{faugray!28}}Cat & \only<5>{\cellcolor{faugray!28}}Fox & \only<3>{\cellcolor{faugray!28}}Cat & \only<9>{\cellcolor{faugray!28}}Dog & \only<3>{\cellcolor{faugray!28}}Cat & \only<5>{\cellcolor{faugray!28}}Dog & \only<9>{\cellcolor{faugray!28}}Fox & \only<9>{\cellcolor{faugray!28}}Fox \\ \hline
		\end{tabular}
	\end{center}

	\vspace*{0.2cm}

	\visible<2->{
		\begin{itemize}
			\item \textbf{Resulting confusion matrix\only<2->{\footnote{We want to evaluate the classification model with regard to the class \textit{Cat}}}:}
		\end{itemize}
		\begin{center}
			\begin{tabular}{lp{1cm}p{1cm}p{1cm}p{1cm}}
				                                                           &                                                                 & \multicolumn{2}{c}{\textit{Predicted Class}}                                                       & \multicolumn{1}{l}{}                                                                                                                                                         \\ \cline{3-4}
				                                                           & \multicolumn{1}{l|}{}                                           & \multicolumn{1}{c|}{\cellcolor{faugray!62}$\text{Cat}$}                                            & \multicolumn{1}{c|}{\cellcolor{faugray!62}$\neg \text{Cat}$}                                                & \multicolumn{1}{l}{\textit{Total}}                             \\ \cline{2-5}
				\multicolumn{1}{c|}{}                                      & \multicolumn{1}{c|}{\cellcolor{faugray!62}$\text{Cat}$}         & \multicolumn{1}{c|}{\only<2-3>{\cellcolor{faugray!28}}\only<-2>{\textbf{TP}}\only<3->{\textbf{3}}} & \multicolumn{1}{c|}{\only<4-5>{\cellcolor{faugray!28}}\only<-4>{\textbf{FN}}\only<5->{\textbf{2}}}          & \multicolumn{1}{c}{\only<-4>{\textbf{P}}\only<5->{\textbf{5}}} \\ \cline{2-4}
				\multicolumn{1}{c|}{\multirow{-2}{*}{\textit{True Class}}} & \multicolumn{1}{c|}{\cellcolor{faugray!62}$\neg \text{Cat}$}    & \multicolumn{1}{c|}{\only<6-7>{\cellcolor{faugray!28}}\only<-6>{\textbf{FP}}\only<7->{\textbf{1}}} & \multicolumn{1}{c|}{\textbf{\only<8-9>{\cellcolor{faugray!28}}\only<-8>{\textbf{TN}}\only<9->{\textbf{4}}}} & \multicolumn{1}{c}{\only<-8>{\textbf{N}}\only<9->{\textbf{5}}} \\ \cline{2-5}
				\multicolumn{2}{r|}{\textit{Total}}                        & \multicolumn{1}{c}{\only<-6>{\textbf{P'}}\only<7->{\textbf{4}}} & \multicolumn{1}{c|}{\only<-8>{\textbf{N'}}\only<9->{\textbf{6}}}                                   & \multicolumn{1}{c}{\only<-8>{\textbf{P+N}}\only<9->{\textbf{10}}}                                                                                                            \\
				                                                           &                                                                 &                                                                                                    &                                                                                                             &
			\end{tabular}
		\end{center}
	}

\end{frame}

\begin{frame}{Evaluation Metrics: Example (II)}

	\vspace*{-1em}

	\begin{center}
		\begin{tabular}{lp{1cm}p{1cm}p{1cm}p{1cm}}
			                                                           &                                                              & \multicolumn{2}{c}{\textit{Predicted Class}}                                                                                           & \multicolumn{1}{l}{}                                                                                                                                                                                                                                                 \\ \cline{3-4}
			                                                           & \multicolumn{1}{l|}{}                                        & \multicolumn{1}{c|}{\cellcolor{faugray!62}$\text{Cat}$}                                                                                & \multicolumn{1}{c|}{\cellcolor{faugray!62}$\neg \text{Cat}$}                                                                      & \multicolumn{1}{l}{\textit{Total}}                                                                                               \\ \cline{2-5}
			\multicolumn{1}{c|}{}                                      & \multicolumn{1}{c|}{\cellcolor{faugray!62}$\text{Cat}$}      & \multicolumn{1}{c|}{\only<2,6,10,12>{\cellcolor{faugray!28}{\rlap{\hspace{0.8em}\color{darkgray}\scriptsize\textbf{(TP)}}}}\textbf{3}} & \multicolumn{1}{c|}{\only<4,12>{\cellcolor{faugray!28}{\rlap{\hspace{0.8em}\color{darkgray}\scriptsize\textbf{(FN)}}}}\textbf{2}} & \multicolumn{1}{c}{\only<2,4,6>{\cellcolor{faugray!28}{\rlap{\hspace{0.8em}\color{darkgray}\scriptsize\textbf{(P)}}}}\textbf{5}} \\ \cline{2-4}
			\multicolumn{1}{c|}{\multirow{-2}{*}{\textit{True Class}}} & \multicolumn{1}{c|}{\cellcolor{faugray!62}$\neg \text{Cat}$} & \multicolumn{1}{c|}{\only<4,10>{\cellcolor{faugray!28}{\rlap{\hspace{0.8em}\color{darkgray}\scriptsize\textbf{(FP)}}}}\textbf{1}}      & \multicolumn{1}{c|}{\only<2,8>{\cellcolor{faugray!28}{\rlap{\hspace{0.8em}\color{darkgray}\scriptsize\textbf{(TN)}}}}\textbf{4}}  & \multicolumn{1}{c}{\only<2,4,8>{\cellcolor{faugray!28}{\rlap{\hspace{0.8em}\color{darkgray}\scriptsize\textbf{(N)}}}}\textbf{5}} \\ \cline{2-5}
			\multicolumn{2}{r|}{\textit{Total}}                        & \multicolumn{1}{c}{\textbf{4}}                               & \multicolumn{1}{c|}{\textbf{6}}                                                                                                        & \multicolumn{1}{c}{\textbf{10}}                                                                                                                                                                                                                                      \\
			                                                           &                                                              &                                                                                                                                        &                                                                                                                                   &
		\end{tabular}
	\end{center}

	\vspace*{-0.25cm}

	\rule{\textwidth}{0.4pt}

	\vspace*{-0.25cm}

	\begin{columns}
		\begin{column}{0.45\textwidth}
			\begin{center}
				\textbf{Calculations:}
			\end{center}
		\end{column}
		\begin{column}{0.45\textwidth}
			\begin{center}
				\textbf{Results:}
			\end{center}
		\end{column}
	\end{columns}

	\vspace*{-0.05cm}

	\begin{columns}
		\begin{column}{0.45\textwidth}
			% Accuracy
			\only<1-2>{
				\begin{align*}
					\text{Accuracy} & = \frac{\text{TP} + \text{TN}}{\text{P} +  \text{N}}       \\
					                & = \visible<2->{ \frac{3 + 4}{5 + 5} = \frac{7}{10} = 70\%}
				\end{align*}
			}
			% Error Rate
			\only<3-4>{
				\begin{align*}
					\text{Error Rate} & = \frac{\text{FP} + \text{FN}}{\text{P} + \text{N}}       \\
					                  & = \visible<4->{\frac{1 + 2}{5 + 5} = \frac{3}{10} = 30\%}
				\end{align*}
			}
			% Sensitivity
			\only<5-6>{
				\begin{align*}
					\text{Sensitivity} & = \frac{\text{TP}}{\text{P}}       \\
					                   & = \visible<6->{\frac{3}{5} = 60\%}
				\end{align*}
			}
			% Specificity
			\only<7-8>{
				\begin{align*}
					\text{Specificity} & = \frac{\text{TN}}{\text{N}}       \\
					                   & = \visible<8->{\frac{4}{5} = 80\%}
				\end{align*}
			}
			% Precision
			\only<9-10>{
				\begin{align*}
					\text{Precision} & = \frac{\text{TP}}{\text{TP} + \text{FP}}             \\
					                 & = \visible<10->{\frac{3}{3 + 1} = \frac{3}{4} = 75\%}
				\end{align*}
			}
			% Recall
			\only<11-12>{
				\begin{align*}
					\text{Recall} & = \frac{\text{TP}}{\text{TP} + \text{FN}}             \\
					              & = \visible<12->{\frac{3}{3 + 2} = \frac{3}{5} = 60\%}
				\end{align*}
			}
			% F1-Measure
			\only<13-14>{
				\begin{align*}
					\text{F}_1 & = \frac{2 \cdot \text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}} \\
					           & = \visible<14->{\frac{2 \cdot 0.75 \cdot 0.6}{0.75 + 0.6} \approx 0.6667 \approx 67\%}
				\end{align*}
			}

		\end{column}
		\begin{column}{0.225\textwidth}
			\begin{align*}
				\visible<2->{\text{Accuracy}    & = 70\% \\}
				\visible<4->{\text{Error Rate}  & = 30\% \\}
				\visible<6->{\text{Sensitivity} & = 60\% \\}
				\visible<8->{\text{Specificity} & = 80\% \\}
			\end{align*}
		\end{column}
		\begin{column}{0.225\textwidth}
			\begin{align*}
				\visible<10->{\text{\only<14>{\color{faugray}}Precision} & = 75\% \\}
				\visible<12->{\text{\only<14>{\color{faugray}}Recall}    & = 60\% \\}
				\visible<14->{\text{F}_1                                 & \approx 67\% \\}
			\end{align*}
		\end{column}
	\end{columns}
\end{frame}


\subsection{Evaluation Strategies}

\begin{frame}{Evaluation Strategies}
	\begin{itemize}
		\item \textbf{We will take a look at two types of evaluation strategies:}
		      \begin{itemize}
			      \item \textbf{\color{airforceblue}Methods to split data into training and test sets:} \\
			            \begin{enumerate}
				            \item Holdout method
				            \item Cross validation
			            \end{enumerate}
			      \item \textbf{\color{airforceblue}Methods to compare classification models and their settings:} \\
			            \begin{enumerate}
				            \item Receiver Operating Characteristics (ROC) curve
			            \end{enumerate}
		      \end{itemize}
		\item \textbf{Of course, there are many many more evaluation strategies}
	\end{itemize}
\end{frame}


\begin{frame}{Evaluation Strategies: Holdout Method}

	\begin{itemize}
		\item \textbf{Easy way to split a dataset: {\color{airforceblue} The Holdout Method}}
		      \begin{itemize}
			      \item Randomly assign tuples into two independent sets:
			            \begin{itemize}
				            \item \textbf{\color{airforceblue}Training set} (E.g., $2/3$) for model construction.
				            \item \textbf{\color{airforceblue}Test set} (E.g., $1/3$) for accuracy estimation.
			            \end{itemize}
			      \item Random sampling: a variation of holdout that repeats holdout $k$ times.
			            \begin{itemize}
				            \item Create an average accuracy over all experiments.
			            \end{itemize}
		      \end{itemize}
	\end{itemize}

\end{frame}

\begin{frame}{Evaluation Strategies: Cross Validation}
	\begin{columns}[T]
		\begin{column}[T]{0.45\textwidth}
			\begin{itemize}
				\item \textbf{More robust than holdout method: {\color{airforceblue} Cross Validation}}
				\item \textbf{In this case: {\color{airforceblue} $k$-fold cross validation}}
				      \begin{itemize}
					      \item Randomly partition the data into $k$ mutually exclusive subsets (folds).
					      \item At each iteration, use one fold as test set and the others as training set.
					      \item Average accuracy of all iterations.
				      \end{itemize}
			\end{itemize}

		\end{column}

		\begin{column}[T]{0.45\textwidth}
			\centering
			\vspace{.3em}
			\textbf{Example:} $k$-fold cross validation with $k=5$\\\medskip

			\small
			\begin{tabular}[c]{l *5{|p{2em}}|}
				            & \multicolumn{5}{c|}{$\leftarrow$ Total Number of Tuples $\longrightarrow$}                                                                                                     \\\cline{2-6}\revealcline
				Iteration 1 & \cellcolor{faugray!50}                                                     &                        &                        &                        &                        \\\cline{2-6}\noalign{\vskip1ex}\cline{2-6}\revealcline
				Iteration 2 &                                                                            & \cellcolor{faugray!50} &                        &                        &                        \\\cline{2-6}\noalign{\vskip1ex}\cline{2-6}\revealcline
				Iteration 3 &                                                                            &                        & \cellcolor{faugray!50} &                        &                        \\\cline{2-6}\noalign{\vskip1ex}\cline{2-6}\revealcline
				Iteration 4 &                                                                            &                        &                        & \cellcolor{faugray!50} &                        \\\cline{2-6}\noalign{\vskip1ex}\cline{2-6}\revealcline
				Iteration 5 &                                                                            &                        &                        &                        & \cellcolor{faugray!50} \\\cline{2-6}\noalign{\vskip1ex}
			\end{tabular}

			\begin{tabular}[c]{|p{2em}|l|p{2em}|l}
				\cline{1-1}\cline{3-3}
				 & Training & \cellcolor{faugray!50} & Validation \\
				\cline{1-1}\cline{3-3}
			\end{tabular}
		\end{column}
	\end{columns}

\end{frame}

\begin{frame}{Evaluation Strategies: ROC Curve}
	\vspace*{-1.5em}
	\begin{columns}
		\begin{column}{0.6\textwidth}
			\begin{itemize}
				\item \textbf{Receiver Operating Characteristics (ROC) curve:}
				      \begin{itemize}
					      \item Visualizes the performance of a classification model:
					            \begin{itemize}
						            \item Shows the performance of a model at different settings/thresholds.
						            \item Plots the True Positive Rate (TPR) \\ against the False Positive Rate (FPR).
						            \item Shows the trade-off between sensitivity and specificity.
					            \end{itemize}
					      \item The closer the curve is to the top-left corner, the better the model. \\
					            $\Rightarrow$ \textbf{\color{airforceblue}The area under the ROC curve (AUC) is a measure of the model's accuracy.}
				      \end{itemize}


			\end{itemize}
		\end{column}
		\begin{column}{0.4\textwidth}
			\vspace*{-1.5em}
			\begin{figure}
				\centering
				\includegraphics[width=\textwidth]{img/roc-curve.png}
			\end{figure}
			\vspace*{-0.5em}
		\end{column}
	\end{columns}
\end{frame}
