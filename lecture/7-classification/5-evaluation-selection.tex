\section{Model Evaluation}\label{section:evaluation}

\begin{frame}{Model Evaluation}
	\begin{itemize}
		\item \textbf{Evaluation metrics:}
		      \begin{itemize}
			      \item How can we measure accuracy?
			      \item Other metrics to consider?
		      \end{itemize}
		\item \textbf{Use {\color{airforceblue}test} set of class-labeled tuples instead of training set when assessing accuracy.}
		\item \textbf{Methods for estimating a classifier's accuracy:}
		      \begin{itemize}
			      \item Holdout method, random subsampling.
			      \item Cross-validation.
			      \item Bootstrap.
		      \end{itemize}
		\item \textbf{Comparing classifiers:}
		      \begin{itemize}
			      \item Confidence intervals.
			      \item Cost-benefit analysis and ROC curves.
		      \end{itemize}
	\end{itemize}
\end{frame}

\subsection{Evaluation Metrics}

\begin{frame}{Confusion Matrix}

	\vspace*{-1.5em}

	\begin{center}
		\begin{tabular}{lp{1cm}p{1cm}p{1cm}p{1cm}}
			                                                           &                                                                & \multicolumn{2}{c}{\textit{Predicted Class}}              & \multicolumn{1}{l}{}                                                                                \\ \cline{3-4}
			                                                           & \multicolumn{1}{l|}{}                                          & \multicolumn{1}{c|}{\cellcolor{faugray!62}\textbf{$C_1$}} & \multicolumn{1}{c|}{\cellcolor{faugray!62}\textbf{$\neg C_1$}} & \multicolumn{1}{l}{\textit{Total}} \\ \cline{2-5}
			\multicolumn{1}{c|}{}                                      & \multicolumn{1}{c|}{\cellcolor{faugray!62}\textbf{$C_1$}}      & \multicolumn{1}{c|}{\textbf{TP}}                          & \multicolumn{1}{c|}{\textbf{FN}}                               & \multicolumn{1}{c}{\textbf{P}}     \\ \cline{2-4}
			\multicolumn{1}{c|}{\multirow{-2}{*}{\textit{True class}}} & \multicolumn{1}{c|}{\cellcolor{faugray!62}\textbf{$\neg C_1$}} & \multicolumn{1}{c|}{\textbf{FP}}                          & \multicolumn{1}{c|}{\textbf{TN}}                               & \multicolumn{1}{c}{\textbf{N}}     \\ \cline{2-5}
			\multicolumn{2}{r|}{\textit{Total}}                        & \multicolumn{1}{c}{\textbf{P'}}                                & \multicolumn{1}{c|}{\textbf{N'}}                          & \multicolumn{1}{c}{\textbf{P+N}}                                                                    \\
			                                                           &                                                                &                                                           &                                                                &
		\end{tabular}
	\end{center}

	\vspace*{-0.5cm}

	\begin{itemize}
		\item \textbf{Confusion Matrix:}
		      \begin{itemize}
			      \item Summarizes the results of a classification model.
			      \item Shows the number of correct and incorrect predictions for each class.
			      \item \textbf{\color{airforceblue}Correctly classified tuples:}
			            \begin{itemize}
				            \item \textbf{True Positives (TP)}: Positive tuples correctly classified as positive.
				            \item \textbf{True Negatives (TN)}: Negative tuples correctly classified as negative.
			            \end{itemize}
			      \item \textbf{\color{airforceblue}Incorrectly classified tuples:}
			            \begin{itemize}
				            \item \textbf{False Positives (FP)}: Negative tuples incorrectly classified as positive.
				            \item \textbf{False Negatives (FN)}: Positive tuples incorrectly classified as negative.
			            \end{itemize}
		      \end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}{Accuracy and Error Rate}

	\vspace*{-1.5em}

	\begin{center}
		\begin{tabular}{lp{1cm}p{1cm}p{1cm}p{1cm}}
			                                                           &                                                                & \multicolumn{2}{c}{\textit{Predicted Class}}              & \multicolumn{1}{l}{}                                                                                \\ \cline{3-4}
			                                                           & \multicolumn{1}{l|}{}                                          & \multicolumn{1}{c|}{\cellcolor{faugray!62}\textbf{$C_1$}} & \multicolumn{1}{c|}{\cellcolor{faugray!62}\textbf{$\neg C_1$}} & \multicolumn{1}{l}{\textit{Total}} \\ \cline{2-5}
			\multicolumn{1}{c|}{}                                      & \multicolumn{1}{c|}{\cellcolor{faugray!62}\textbf{$C_1$}}      & \multicolumn{1}{c|}{\textbf{TP}}                          & \multicolumn{1}{c|}{\textbf{FN}}                               & \multicolumn{1}{c}{\textbf{P}}     \\ \cline{2-4}
			\multicolumn{1}{c|}{\multirow{-2}{*}{\textit{True class}}} & \multicolumn{1}{c|}{\cellcolor{faugray!62}\textbf{$\neg C_1$}} & \multicolumn{1}{c|}{\textbf{FP}}                          & \multicolumn{1}{c|}{\textbf{TN}}                               & \multicolumn{1}{c}{\textbf{N}}     \\ \cline{2-5}
			\multicolumn{2}{r|}{\textit{Total}}                        & \multicolumn{1}{c}{\textbf{P'}}                                & \multicolumn{1}{c|}{\textbf{N'}}                          & \multicolumn{1}{c}{\textbf{P+N}}                                                                    \\
			                                                           &                                                                &                                                           &                                                                &
		\end{tabular}
	\end{center}

	\vspace*{-0.5cm}

	\begin{columns}
		\begin{column}{0.45\textwidth}
			\visible<2->{
				\begin{itemize}
					\item \textbf{Accuracy:}
					      \begin{itemize}
						      \item Percentage of correctly classified tuples.
					      \end{itemize}
				\end{itemize}
			}
		\end{column}
		\begin{column}{0.45\textwidth}
			\visible<3->{
				\begin{itemize}
					\item \textbf{Error Rate:}
					      \begin{itemize}
						      \item Inverse of accuracy, i.e. percentage of incorrectly classified tuples.
					      \end{itemize}
				\end{itemize}
			}
		\end{column}
	\end{columns}

	\vspace*{-0.5em}

	\begin{columns}
		\begin{column}{0.45\textwidth}
			\visible<2->{
				\begin{align*}
					\text{Accuracy} & = \frac{\text{TP} + \text{TN}}{\text{P} +  \text{N}} \\
				\end{align*}
			}
		\end{column}
		\begin{column}{0.45\textwidth}
			\visible<3->{
				\begin{align*}
					\text{Error Rate} & = 1 - \text{Accuracy}                               \\
					                  & = \frac{\text{FP} + \text{FN}}{\text{P} + \text{N}} \\
				\end{align*}
			}
		\end{column}
	\end{columns}
\end{frame}

\begin{frame}{Sensitivity, Specificity, Precision, and Recall}

	\vspace*{-1.5em}

	\begin{center}
		\begin{tabular}{lp{1cm}p{1cm}p{1cm}p{1cm}}
			                                                           &                                                                & \multicolumn{2}{c}{\textit{Predicted Class}}              & \multicolumn{1}{l}{}                                                                                \\ \cline{3-4}
			                                                           & \multicolumn{1}{l|}{}                                          & \multicolumn{1}{c|}{\cellcolor{faugray!62}\textbf{$C_1$}} & \multicolumn{1}{c|}{\cellcolor{faugray!62}\textbf{$\neg C_1$}} & \multicolumn{1}{l}{\textit{Total}} \\ \cline{2-5}
			\multicolumn{1}{c|}{}                                      & \multicolumn{1}{c|}{\cellcolor{faugray!62}\textbf{$C_1$}}      & \multicolumn{1}{c|}{\textbf{TP}}                          & \multicolumn{1}{c|}{\textbf{FN}}                               & \multicolumn{1}{c}{\textbf{P}}     \\ \cline{2-4}
			\multicolumn{1}{c|}{\multirow{-2}{*}{\textit{True class}}} & \multicolumn{1}{c|}{\cellcolor{faugray!62}\textbf{$\neg C_1$}} & \multicolumn{1}{c|}{\textbf{FP}}                          & \multicolumn{1}{c|}{\textbf{TN}}                               & \multicolumn{1}{c}{\textbf{N}}     \\ \cline{2-5}
			\multicolumn{2}{r|}{\textit{Total}}                        & \multicolumn{1}{c}{\textbf{P'}}                                & \multicolumn{1}{c|}{\textbf{N'}}                          & \multicolumn{1}{c}{\textbf{P+N}}                                                                    \\
			                                                           &                                                                &                                                           &                                                                &
		\end{tabular}
	\end{center}

	\vspace*{-0.5cm}

	\begin{columns}
		\begin{column}{0.45\textwidth}
			\visible<2->{
				\begin{itemize}
					\item \textbf{Sensitivity:}
					      \begin{itemize}
						      \item True positive rate.
					      \end{itemize}
				\end{itemize}
			}
		\end{column}
		\begin{column}{0.45\textwidth}
			\visible<4->{
				\begin{itemize}
					\item \textbf{Recall:}
					      \begin{itemize}
						      \item Measure of completeness.
					      \end{itemize}
				\end{itemize}
			}
		\end{column}
	\end{columns}

	\vspace*{-0.5em}

	\begin{columns}
		\begin{column}{0.45\textwidth}
			\visible<2->{
				\begin{align*}
					\text{Sensitivity} & = \frac{\text{TP}}{\text{P}} \only<6->{= \text{Recall}} \\
				\end{align*}
			}
		\end{column}
		\begin{column}{0.45\textwidth}
			\visible<4->{
				\begin{align*}
					\text{Recall} & =  \frac{\text{TP}}{\text{TP} + \text{FN}} \only<6->{= \text{Sensitivity}} \\
				\end{align*}
			}
		\end{column}
	\end{columns}

	\vspace*{-3.5em}

	\begin{columns}
		\begin{column}{0.45\textwidth}
			\visible<3->{
				\begin{itemize}
					\item \textbf{Specificity:}
					      \begin{itemize}
						      \item True negative rate.
					      \end{itemize}
				\end{itemize}
			}
		\end{column}
		\begin{column}{0.45\textwidth}
			\visible<5->{
				\begin{itemize}
					\item \textbf{Precision:}
					      \begin{itemize}
						      \item Measure of exactness.
					      \end{itemize}
				\end{itemize}
			}
		\end{column}
	\end{columns}

	\vspace*{-0.5em}

	\begin{columns}
		\begin{column}{0.45\textwidth}
			\visible<3->{
				\begin{align*}
					\text{Specificity} & = \frac{\text{TN}}{\text{N}} \\
				\end{align*}
			}
		\end{column}
		\begin{column}{0.45\textwidth}
			\visible<5->{
				\begin{align*}
					\text{Precision} & = \frac{\text{TP}}{\text{TP} + \text{FP}}
				\end{align*}
			}
		\end{column}
	\end{columns}
\end{frame}

\begin{frame}{$\text{\textbf{F}}_\beta$ Measure}

	\vspace*{-1.5em}

	\begin{center}
		\begin{tabular}{lp{1cm}p{1cm}p{1cm}p{1cm}}
			                                                           &                                                                & \multicolumn{2}{c}{\textit{Predicted Class}}              & \multicolumn{1}{l}{}                                                                                \\ \cline{3-4}
			                                                           & \multicolumn{1}{l|}{}                                          & \multicolumn{1}{c|}{\cellcolor{faugray!62}\textbf{$C_1$}} & \multicolumn{1}{c|}{\cellcolor{faugray!62}\textbf{$\neg C_1$}} & \multicolumn{1}{l}{\textit{Total}} \\ \cline{2-5}
			\multicolumn{1}{c|}{}                                      & \multicolumn{1}{c|}{\cellcolor{faugray!62}\textbf{$C_1$}}      & \multicolumn{1}{c|}{\textbf{TP}}                          & \multicolumn{1}{c|}{\textbf{FN}}                               & \multicolumn{1}{c}{\textbf{P}}     \\ \cline{2-4}
			\multicolumn{1}{c|}{\multirow{-2}{*}{\textit{True class}}} & \multicolumn{1}{c|}{\cellcolor{faugray!62}\textbf{$\neg C_1$}} & \multicolumn{1}{c|}{\textbf{FP}}                          & \multicolumn{1}{c|}{\textbf{TN}}                               & \multicolumn{1}{c}{\textbf{N}}     \\ \cline{2-5}
			\multicolumn{2}{r|}{\textit{Total}}                        & \multicolumn{1}{c}{\textbf{P'}}                                & \multicolumn{1}{c|}{\textbf{N'}}                          & \multicolumn{1}{c}{\textbf{P+N}}                                                                    \\
			                                                           &                                                                &                                                           &                                                                &
		\end{tabular}
	\end{center}

	\vspace*{-0.5cm}

	\begin{columns}
		\begin{column}{0.45\textwidth}
			\visible<2->{
				\begin{itemize}
					\item \textbf{$\text{\textbf{F}}_\beta$ Measure}
					      \begin{itemize}
						      \item Combining precision and recall.
						      \item Gives $\beta$-times more weight to precision.
						      \item $\beta > 1$: Minimize false positives.
						      \item $\beta < 1$: Minimize false negatives.
					      \end{itemize}
				\end{itemize}
			}
		\end{column}
		\begin{column}{0.45\textwidth}
			\visible<3->{
				\begin{itemize}
					\item \textbf{$\text{\textbf{F}}_1$ Measure}
					      \begin{itemize}
						      \item Harmonic mean between the measures.
						      \item Equal weight to both measures.
					      \end{itemize}
				\end{itemize}
			}
		\end{column}
	\end{columns}

	\vspace*{-0.5em}

	\begin{columns}
		\begin{column}{0.45\textwidth}
			\visible<2->{
				\begin{align*}
					\text{F}_\beta & = \frac{(1 + \beta^2) \times \text{Precision} \times \text{Recall}}{\beta^2 \times \text{Precision} + \text{Recall}}
				\end{align*}
			}
		\end{column}
		\begin{column}{0.45\textwidth}
			\visible<3->{
				\begin{align*}
					\text{F}_1 & = \frac{2 \times \text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}} \\
				\end{align*}
			}
		\end{column}
	\end{columns}
\end{frame}

\begin{frame}{Evaluation Metrics - Example}
	\centering
	\begin{tabular}{|c|c|c|c|c|}
		\hline
		Actual class/predicted class & cancer = yes & cancer = no   & Total & Recognition ($\%$)  \\\hline
		cancer = yes                 & \textbf{90}  & \textbf{210}  & 300   & 30.00 (sensitivity) \\\hline
		cancer = no                  & \textbf{140} & \textbf{9560} & 9700  & 98.56 (specificity) \\\hline
		Total                        & 230          & 9770          & 10000 & 96.40 (accuracy)    \\\hline
	\end{tabular}\\[0.2cm]
	\begin{itemize}
		\item Precision $= \frac{90}{230} = 39.13 \%$.
		\item Recall $=\frac{90}{300} = 30.00 \%$.
		\item $F_1$-measure = $\frac{2 \cdot 0.3913 \cdot 0.3}{0.3913 + 0.3} = 33.96 \%$.
	\end{itemize}
\end{frame}

\subsection{Evaluation Strategies}


\begin{frame}{Evaluation Strategies: Holdout Method}
	\textbf{Holdout method.}
	\begin{itemize}
		\item Randomly assign tuples into two independent sets:
		      \begin{itemize}
			      \item \textbf{\color{airforceblue}Training set} (E.g., $2/3$) for model construction.
			      \item \textbf{\color{airforceblue}Test set} (E.g., $1/3$) for accuracy estimation.
		      \end{itemize}
		\item Random sampling: a variation of holdout that repeats holdout $k$ times.
		      \begin{itemize}
			      \item Create an average accuracy over all experiments.
		      \end{itemize}
	\end{itemize}

\end{frame}

\begin{frame}{Evaluation Strategies: Cross Validation}
	Most common: $k$-fold cross validation ($k=10$ is popular).

	\begin{columns}[T]
		\begin{column}[T]{0.5\textwidth}
			\begin{itemize}
				\item Randomly partition the data into $k$ mutually exclusive subsets (folds), each approximately equal size.
				\item At $i$-th iteration, use $D_i$ as test set and the others as training set.
				\item Average accuracy of all iterations.
				\item \textbf{Leave-one-out}: $k$ folds, on $i$-th iteration leave out $i$-th fold; for small-sized data.
				\item \textbf{Stratified cross-validation}: For every class select a simple random sample of tuples. Results in subsets with approximately the same distribution.
			\end{itemize}

		\end{column}

		\begin{column}[T]{0.5\textwidth}
			\centering
			\vspace{.3em}
			\textbf{Example:} $k$-fold cross validation with $k=5$\\\medskip

			\small
			\begin{tabular}[c]{l *5{|p{2em}}|}
				            & \multicolumn{5}{c|}{$\leftarrow$ Total Number of Tuples $\longrightarrow$}                                                                                                         \\\cline{2-6}\revealcline
				Iteration 1 & \cellcolor{faugreen!25}                                                    &                         &                         &                         &                         \\\cline{2-6}\noalign{\vskip1ex}\cline{2-6}\revealcline
				Iteration 2 &                                                                            & \cellcolor{faugreen!25} &                         &                         &                         \\\cline{2-6}\noalign{\vskip1ex}\cline{2-6}\revealcline
				Iteration 3 &                                                                            &                         & \cellcolor{faugreen!25} &                         &                         \\\cline{2-6}\noalign{\vskip1ex}\cline{2-6}\revealcline
				Iteration 4 &                                                                            &                         &                         & \cellcolor{faugreen!25} &                         \\\cline{2-6}\noalign{\vskip1ex}\cline{2-6}\revealcline
				Iteration 5 &                                                                            &                         &                         &                         & \cellcolor{faugreen!25} \\\cline{2-6}\noalign{\vskip1ex}
			\end{tabular}

			\begin{tabular}[c]{|p{2em}|l|p{2em}|l}
				\cline{1-1}\cline{3-3}
				 & Training & \cellcolor{faugreen!25} & Validation \\
				\cline{1-1}\cline{3-3}
			\end{tabular}
		\end{column}
	\end{columns}

\end{frame}

\begin{frame}{Receiver Operating Characteristics (ROC) Curve}
	\vspace*{-1.5em}
	\begin{columns}
		\begin{column}{0.6\textwidth}
			\begin{itemize}
				\item Visual comparison of classification models.
				\item Compares and shows \textit{trade-off} between TPR and FPR:
				      \begin{itemize}
					      \item True Positive Rate (\textbf{TPR}): Proportion of positive tuples correctly classified as positive.\\
					            $\rightarrow$ sensitivity or recall $= \frac{\text{TP}}{\text{P}}$
					      \item False Positive Rate (\textbf{FPR}:) Proportion of negative tuples incorrectly classified as positive.\\
					            $\rightarrow \text{FPR} = \frac{\text{FP}}{\text{N}} = 1 - \text{Specificity}$
				      \end{itemize}

				\item \textbf{The area under the ROC curve is a
						      {\color{airforceblue}measure of the accuracy} of the model.}
				      Maximum area of $1.0$ for a perfect classifier.
				\item \textbf{The closer to the diagonal line (i.e. the closer the
					      area is to $0.5$), the less accurate is the model.}

			\end{itemize}
		\end{column}
		\begin{column}{0.4\textwidth}
			\vspace*{-1.5em}
			\begin{figure}
				\centering
				\includegraphics[width=\textwidth]{img/roc-curve.png}
			\end{figure}
			\vspace*{-0.5em}
			\scriptsize
			How to draw: Order tuples in decreasing order of probability.
			\begin{itemize}
				\item If TP move up TPR and plot point.
				\item If negative tuple classified as positive: move both FPR and FPR.
			\end{itemize}
		\end{column}
	\end{columns}
\end{frame}

\begin{frame}{Other Aspects of Model Selection}
	\begin{itemize}
		\item \textbf{Speed}
		      \begin{itemize}
			      \item Computational cost to train a classifier.
			      \item Time to use model (prediction time).
		      \end{itemize}
		\item \textbf{Robustness}, i. e. the ability to make accurate predictions.
		      \begin{itemize}
			      \item Noisy data.
			      \item Missing values.
		      \end{itemize}
		\item \textbf{Scalability}, i . e. efficient construction of classifiers on an abundant amount of training tuples.
		\item \textbf{Interpretability}, refers to understanding and insight
		      \begin{itemize}
			      \item Typically subjective and difficult to access.
			      \item Decision trees and classification rules are easy to interpret, but interpretability degrades with the size.
		      \end{itemize}
		\item \textit{Other measures} such as goodness of rules, decision-tree size or compactness of classification rules.
	\end{itemize}
\end{frame}
