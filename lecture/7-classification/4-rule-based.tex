\section{Rule-Based Classification}

\begin{frame}{Using \uppercase{if-then} Rules for Classification}
	\begin{itemize}
		\item \textbf{Represent the knowledge in the form of {\color{airforceblue}IF-THEN rules}.}
		      \begin{itemize}
			      \item E.g., if \texttt{age} $\leq 30$ AND \texttt{student} = "yes" THEN buys\_computer = "yes".
			      \item Readable.
		      \end{itemize}
		\item \textbf{Rule {\color{airforceblue}antecedent/precondition} vs. rule {\color{airforceblue}consequent}}.
		\item \textbf{Assessment of a rule R: coverage and accuracy.}
		      \begin{itemize}
			      \item $n_{\text{covers}} = \#$ of tuples covered by $R$ (antecedent if true).
			      \item $n_{\text{correct}} = \#$ of tuples correctly classified by $R$.
			      \item $\text{coverage}(R) = \frac{n_{\text{covers}}}{|D|}$ with $D$ training data set.
			      \item $\text{accuracy}(R) = \frac{n_{\text{correct}}}{n_{\text{covers}}}$.
		      \end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}[c]{Potential Problems of Rule-Based Classification}
	\centering
	\huge
	\begin{enumerate}
		\item More than one rule is triggered.
		\item No rule is triggered.
	\end{enumerate}
\end{frame}

\begin{frame}{Potential Problems of Rule-based Classification: Solutions}
	\begin{enumerate}
		\item \textbf{More than one rule is triggered: {\color{airforceblue}conflict resolution}.}
		      \begin{itemize}
			      \item \textbf{\color{airforceblue}Size ordering:}
			            \begin{itemize}
				            \item Assign the highest priority to the triggered rule that has the "toughest" requirement \\ (i.e., rule with most used attribute in condition).
			            \end{itemize}
			      \item \textbf{\color{airforceblue}Class-based ordering:}
			            \begin{itemize}
				            \item Decreasing order of prevalence or misclassification cost per class.
				            \item No order of rules within class $\rightarrow$ disjunction (logical \texttt{OR}) between rules.
			            \end{itemize}
			      \item \textbf{\color{airforceblue}Rule-based ordering} (decision list):
			            \begin{itemize}
				            \item Rules are organized into one long priority list,\\
				                  according to some measure of rule quality, or by experts.
				            \item Rules \underline{must} be applied in this particular order to avoid conflict.
			            \end{itemize}
		      \end{itemize}
		\item \textbf{No rule is triggered.}
		      \begin{itemize}
			      \item Use a fallback/default rule.
			      \item Always evaluated as the last rule, if and only if other rules are not covered by some tuple, i. e. no rules have been triggered.
		      \end{itemize}
	\end{enumerate}
\end{frame}

\begin{frame}{Rule Extraction from a Decision Tree}
	\begin{itemize}
		\item \textbf{Rules are {\color{airforceblue}easier to understand} than large trees.}
		\item \textbf{Rule can be created for {\color{airforceblue}each path from the root to a leaf.}}
		      \begin{itemize}
			      \item The leaf holds the class prediction.
		      \end{itemize}
		\item \textbf{Each attribute-value pair along the path forms a conjunction:}
	\end{itemize}
	\vspace*{1em}
	\begin{columns}
		\begin{column}{0.55\textwidth}
			\textbf{Example:}
			\begin{enumerate}
				\item IF \texttt{age} $\leq$ 30 AND \texttt{student} = "no" \\
				      THEN \texttt{buys\_computer} = "no".
				\item IF \texttt{age} $\leq$ 30 AND \texttt{student} = "yes" \\
				      THEN \texttt{buys\_computer} = "yes".
				\item IF \texttt{age}== $31\ldots40$ THEN \texttt{buys\_computer} = "yes".
				\item \dots
			\end{enumerate}
		\end{column}
		\begin{column}{0.45\textwidth}
			\vspace*{-1em}
			\begin{figure}[h]
				\centering
				\input{7-classification/tree-example.tex}
			\end{figure}
		\end{column}
	\end{columns}
\end{frame}

\begin{frame}{Rule Induction: Sequential Covering Method}
	\begin{itemize}
		\item \textbf{Sequential covering algorithm:}
		      \begin{itemize}
			      \item Extracts rules directly from training data.
		      \end{itemize}
		\item \textbf{Typical sequential covering algorithms:}
		      \begin{itemize}
			      \item FOIL, AQ, CN2, RIPPER.
		      \end{itemize}
		\item \textbf{Rules are learned {\color{airforceblue}sequentially}.}
		      \begin{itemize}
			      \item Each rule for a given class $C_i$ will cover many tuples of $C_i$, but none (or few) of the tuples of other classes.
		      \end{itemize}
		\item \textbf{Algorithm sketch:}
		      \begin{itemize}
			      \item Rules are learned one at a time.
			      \item Each time a rule is learned, the tuples covered by the rule are removed.
			      \item The process repeats on the remaining tuples unless termination condition, e.g., when no more training examples left or when the quality of a rule returned is below a user-specified threshold.
		      \end{itemize}
		\item \textbf{Compare with decision-tree induction:}
		      \begin{itemize}
			      \item That was learning a set of rules simultaneously.
		      \end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}{Sequential Covering Algorithm (I)}
	% REVIEW: This header is a bit confusing after concrete Sequential Covering Algortihms are presented on the previous slide. One wonders which of the algorithms is being outlined here. Since "FOIL_Gain" is mentioned on the next slide, I assume that the algorithm outlined here is supposed to be FOIL. Accordingly, I would then also mention this in the three headers.
	\begin{itemize}
		\item \textbf{While (enough target tuples left):}
		      \begin{itemize}
			      \item generate a rule;
			      \item remove positive target tuples satisfying this rule;
		      \end{itemize}
		      \centering
		      \begin{tikzpicture}
			      \draw[fill=airforceblue] (0,0) ellipse (5.2 and 2.5) (0,0) node [text=black] {};
			      \draw[fill=white] (0,1) ellipse (2 and 1.2) (0,0) node [text=black] {};
			      \draw[fill=white] (-3,-0.2) ellipse (2 and 1.2) (0,0) node [text=black] {};
			      \draw[fill=white] (3,0) ellipse (2 and 1.2) (0,0) node [text=black] {};
			      \node at (0,1.1) (a1) {Examples covered};
			      \node at (0,0.8) (a2) {by rule 2};
			      \node at (3,0.1) (b1) {Examples covered};
			      \node at (3,-0.2) (b2) {by rule 3};
			      \node at (-3,-0.2) (c1) {Examples covered};
			      \node at (-3,-0.5) (c2) {by rule 1};
			      \node at (-1,-1.5) (d1) {\textbf{Positive}};
			      \node at (-1,-1.8) (d2) {\textbf{examples}};
		      \end{tikzpicture}
	\end{itemize}
\end{frame}

\begin{frame}{Sequential Covering Algorithm (II)}
	\begin{itemize}
		\item \textbf{To generate a rule:}
		      \begin{itemize}
			      \item \textbf{while}(true:)
			            \begin{itemize}
				            \item find the best predicate $p$ (attribute = value);
				            \item \textbf{if} \texttt{FOIL\_Gain}(p) > threshold
				            \item \textbf{then} add $p$ to current rule;
				            \item \textbf{else} break;
			            \end{itemize}
		      \end{itemize}
	\end{itemize}
	\centering
	\begin{tikzpicture}
		\draw[fill=red!20] (-3,0) rectangle (1,4) (0,0) node [text=black] {};
		\draw[fill=airforceblue!20] (6,0) rectangle (0,4) (0,0) node [text=black] {};
		\node at (3,0.5) (a1) {Negative examples};
		\node at (-1.5,0.5) (a1) {Positive examples};
		\uncover<2->{
			\draw[fill=yellow!20,fill opacity=0.7] (-0.7,2.5) ellipse (2 and 1.2) (0,0) node [text=black] {};
			\node at (-0.7,3) {$A3=1$};
		}
		\uncover<3->{
			\draw[fill=yellow!20,fill opacity=0.7] (-0.7,2.5) ellipse (1.8 and 1) (0,0) node [text=black] {};
			\node at (-0.7,2.7) {$A3=1 \&\& A1=2$};
		}
		\uncover<4->{
			\draw[fill=yellow!20,fill opacity=0.7] (-0.7,2.5) ellipse (1.6 and 0.8) (0,0) node [text=black] {};
			\node at (-0.7,2.4) {$A3=1 \&\& A1=2$};
			\node at (-0.7,2.1) {$\&\& A8=5$};
		}
	\end{tikzpicture}
\end{frame}

% TODO: Review again and cosmetics
\begin{frame}{Sequential Covering Algorithm (III)}
	\begin{itemize}
		\item \textbf{Start with the most general rule possible:}
		      \begin{itemize}
			      \item Condition = empty.
		      \end{itemize}
		\item \textbf{Add new attributes by adopting a greedy depth-first strategy.}
		      \begin{itemize}
			      \item Pick the one that improves the rule quality most.
			      \item Current rule $R$: IF condition THEN class = c.
			      \item New rule $R'$: IF condition' THEN class = c,
			      \item $pos/neg$ are $\#$ of positive/negative tuples covered by $R$.
		      \end{itemize}
		\item \textbf{Rule-quality measures.}
		      \begin{itemize}
			      \item Must consider both coverage and accuracy.
			      \item \texttt{FOIL\_Gain} (from \texttt{FOIL} - First-Order Inductive Learner):
			            \begin{align*}
				            \text{FOIL\_Gain} = \text{pos}' \left( \log_2 \frac{\text{pos}'}{\text{pos}' + \text{neg}'} - \log_2 \frac{\text{pos}}{\text{pos}+\text{neg}} \right).
			            \end{align*}
			      \item Favors rules that have high accuracy and cover many positive tuples.
		      \end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}{Rule Pruning}
	\begin{itemize}
		\item \textbf{Danger of {\color{airforceblue}overfitting}.}
		\item \textbf{Removing a conjunct (attribute test),}
		      \begin{itemize}
			      \item if pruned version of rule has greater quality,\\
			            assessed on an independent set of test tuples (called "pruning set").
		      \end{itemize}
		\item \textbf{FOIL uses:}
		      \begin{align*}
			      \text{FOIL\_Prune}(R) = \frac{\text{pos}-\text{neg}}{\text{pos}+\text{neg}}.
		      \end{align*}
		\item If $\text{FOIL\_Prune}$ is higher for the pruned version of $R$, prune $R$.
	\end{itemize}
\end{frame}
