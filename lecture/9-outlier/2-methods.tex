\section{Outlier-Detection Methods}

\begin{frame}{How can we detect outliers?}
	\begin{itemize}
		\item \textbf{Two ways to categorize outlier-detection methods:}
		      \begin{itemize}
			      \item Based on whether \textbf{\color{airforceblue}user-labeled examples of outliers} can be obtained: \\
			            I.e. supervised, semi-supervised vs. unsupervised methods.
			      \item Based on \textbf{\color{airforceblue}assumptions} about normal data and outliers: \\
			            I.e. statistical, proximity-based, and clustering-based methods.
		      \end{itemize}
	\end{itemize}
\end{frame}


\begin{frame}{Outlier Detection I}
	\begin{itemize}
		\item \textbf{Supervised Methods:}
		      \begin{itemize}
			      \item Modeling outlier detection as a \textbf{classification problem}:\\
			            Samples examined by domain experts used for training \& testing.
			      \item Methods for learning a classifier for outlier detection effectively:
			            \begin{itemize}
				            \item Model normal objects \& report those not matching the model as outliers.
				            \item Model outliers and treat those not matching the model as normal.
			            \end{itemize}
			      \item \textbf{Challenges:}
			            \begin{itemize}
				            \item Imbalanced classes, i.e., outliers are rare: \\
				                  Boost the outlier class and make up some artificial outliers.
				            \item Catch as many outliers as possible, \\
				                  i.e., recall is more important than accuracy \\
				                  (i.e., not mislabeling normal objects as outliers).
			            \end{itemize}
		      \end{itemize}
	\end{itemize}
\end{frame}


\begin{frame}
	\frametitle{Outlier Detection II}
	\begin{itemize}
		\item \textbf{Assume the {\color{airforceblue}normal objects are somewhat "clustered"} into multiple groups, each having some distinct features.}
		      \item\textbf{An outlier is expected to be {\color{airforceblue}far away from any group} of normal objects.}
		\item \textbf{Weakness: Can't detect collective outliers effectively.}
		      \begin{itemize}
			      \item Normal objects may not share any strong pattern, \\
			            but the collective outliers may have high similarity in a small area.
		      \end{itemize}
		\item \textbf{I.e., in some intrusion or virus detection, normal activities are diverse.}
		      \begin{itemize}
			      \item Unsupervised methods may have a high false-positive rate, \\
			            but still miss many real outliers.
			      \item Supervised methods can be more effective, \\
			            e.g., identify attacking some key resources.
		      \end{itemize}
	\end{itemize}
\end{frame}


\begin{frame}
	\frametitle{Outlier Detection III}
	\begin{itemize}
		\item \textbf{Many clustering methods can be adapted for unsupervised methods:}
		      \begin{itemize}
			      \item Find clusters, then outliers: not belonging to any cluster.
			      \item \textbf{Problem 1:} Hard to distinguish noise from outliers.
			      \item \textbf{Problem 2:} Costly since first clustering, but far less outliers than normal objects.
			      \item Newer methods: tackle outliers directly.
		      \end{itemize}
	\end{itemize}
\end{frame}


\begin{frame}
	\frametitle{Outlier Detection IV}
	\begin{itemize}
		\item \textbf{Situation:}
		      \begin{itemize}
			      \item In many applications, the \textbf{\color{airforceblue}number of labeled data objects is small}:\\
			            Labels could be on outliers only, on normal objects only, or on both.
		      \end{itemize}
		\item \textbf{Semi-supervised outlier detection:}
		      \begin{itemize}
			      \item Regarded as application of semi-supervised learning.
		      \end{itemize}
		\item \textbf{If some {\color{airforceblue}labeled normal objects} are available:}
		      \begin{itemize}
			      \item Use the labeled examples and the proximate \\
			            unlabeled objects to train a model for normal objects.
			      \item Those not fitting the model of normal objects are detected as outliers.
		      \end{itemize}
		\item \textbf{If only some {\color{airforceblue}labeled outliers} are available, \\ that small number may not cover the possible outliers well.}
		      \begin{itemize}
			      \item To improve the quality of outlier detection: get help from models for normal objects learned from unsupervised methods.
		      \end{itemize}
	\end{itemize}
\end{frame}


\begin{frame}{Outlier Detection V: Statistical Methods}
	\tikzoverlay at (11cm,1cm) {\input{9-outlier/general-outlier.tex}};
	\begin{itemize}
		\item (Also known as model-based methods)
		\item Assume that the \textbf{\color{airforceblue}normal data follow some statistical model}.
		      \begin{itemize}
			      \item The data not following the model are outliers.
		      \end{itemize}
		\item \textbf{Example (right figure):}
		      \begin{itemize}
			      \item First use Gaussian distribution $\mathcal{N}_D(x \; \vert \; \mu,\sigma)$ to model the normal data.
			      \item For each object $y$ in region $R$, estimate $\mathcal{N}_D(y \; \vert \; \mu, \sigma)$, the probability that $y$ \\
			            fits the Gaussian distribution.
			      \item If $\mathcal{N}_D(y \; \vert \; \mu, \sigma)$ is very low, $y$ is unlikely generated by the Gaussian model, thus an outlier.
		      \end{itemize}
		      \item\textbf{Effectiveness of statistical methods:}
		      \begin{itemize}
			      \item Highly depends on whether the assumption of statistical model holds in the real data.
		      \end{itemize}
		\item \textbf{There are many kinds of statistical models.}
		      \begin{itemize}
			      \item E.g., parametric vs. non-parametric.
		      \end{itemize}
	\end{itemize}
\end{frame}


\begin{frame}{Outlier Detection (2): Proximity-Based Methods}
	\tikzoverlay at (11cm,1cm) {\input{9-outlier/general-outlier.tex}};
	An object is an outlier if the \textbf{\color{airforceblue}nearest neighbors of the object are far away},\\ i.e., the proximity of the object significantly deviates from the proximity\\ of most of the other objects in the same data set.
	\begin{itemize}

		\item \textbf{Example (right figure):}
		      \begin{itemize}
			      \item Model the proximity of an object using its 3 nearest neighbors.
			      \item Objects in region R are substantially different from other objects in the data set.
			      \item Thus the objects in R are outliers.
		      \end{itemize}
		\item \textbf{Effectiveness of proximity-based methods:}
		      \begin{itemize}
			      \item Highly relies on the proximity measure.
			      \item In some applications, proximity or distance measures cannot be obtained easily.
			      \item Often have a difficulty in finding a group of outliers which are close to each other.
		      \end{itemize}
		\item \textbf{Two major types of proximity-based outlier detection:}
		      \begin{itemize}
			      \item Distance-based vs. density-based.
		      \end{itemize}
	\end{itemize}
\end{frame}


\begin{frame}{Outlier Detection (3): Clustering-Based Methods}
	\tikzoverlay at (11cm,1cm) {\input{9-outlier/general-outlier.tex}};
	Normal data belong to large and dense clusters, whereas outliers belong to\\ \textbf{\color{airforceblue}small or sparse clusters}, or do not belong to any cluster.
	\begin{itemize}

		\item \textbf{Example (right figure): Two clusters.}
		      \begin{itemize}
			      \item All points not in R form a large cluster.
			      \item The two points in R form a tiny cluster, thus are outliers.

		      \end{itemize}
		\item \textbf{Many clustering methods:}
		      \begin{itemize}
			      \item Thus also many clustering-based outlier detection methods.
		      \end{itemize}
		\item \textbf{Clustering is expensive.}
		      \begin{itemize}
			      \item Straightforward adaptation of a clustering method for outlier detection can be costly and does not scale up well for large data sets.
		      \end{itemize}
	\end{itemize}
\end{frame}
