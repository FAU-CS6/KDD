{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data analysis & Preprocessing\n",
    "\n",
    "In this exercise you will get to know the basics from the lectures \"3. Getting to Know Your Data\" and \"4. Preprocessing\" in their practical use and apply them yourself.\n",
    "\n",
    "Since this practice sheet is designed to be used in three sessions, it is roughly divided into three sections:\n",
    "\n",
    "- [2.1. Part One: Getting to Know Your Data](#2.1. Part One: Getting to Know Your Data)\n",
    "- [2.2. Part Two: Preprocessing - Data cleaning & data integration](#2.2. Part Two: Preprocessing - Data cleaning & Data integration)\n",
    "- [2.3. Part Three: Preprocessing - Data reduction, data transformation & data discretization](#2.3. Part Three: Preprocessing - Data reduction, data transformation & data discretization)\n",
    "\n",
    "Of course, depending on how quickly an exercise group progresses in the actual exercise, one of these parts may not be discussed entirely in the affected exercise, or parts of the subsequent part may already be addressed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation: Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
        "tags": [
            "specification"
        ],
        "deletable": false,
        "editable": false
   },
   "outputs": [],
   "source": [
    "# Import the required datasets\n",
    "import tempfile\n",
    "import sqlite3\n",
    "import urllib.request\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation: Download the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
        "tags": [
            "specification"
        ],
        "deletable": false,
        "editable": false
   },
   "outputs": [],
   "source": [
    "# Create a temporary directory\n",
    "dataset_folder = tempfile.mkdtemp()\n",
    "\n",
    "# Get the database\n",
    "urllib.request.urlretrieve(\"https://github.com/FAU-CS6/KDD-Databases/raw/main/AdventureWorks/adventure-works.db\", dataset_folder + \"/adventure-works.db\")\n",
    "\n",
    "# Open connection to the adventure-works.db \n",
    "connection = sqlite3.connect(dataset_folder + \"/adventure-works.db\")\n",
    "\n",
    "# Create the dataframe(s)\n",
    "order_dataframe = pd.read_sql_query(\"SELECT * FROM Product JOIN PurchaseOrderDetail ON Product.ProductID = PurchaseOrderDetail.ProductID\", connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Part One: Getting to Know Your Data\n",
    "\n",
    "In this part you will apply the theoretical knowledge gained in the lecture \"Getting to Know Your Data\". In doing so, you will familiarize yourself step by step with the `order_dataframe` dataframe defined above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1. Structure of the Dataframe\n",
    "\n",
    "Currently you don't know anything about the order dataframe except for the fact that it consists of the two tables `Product` and `PurchaseOrderDetail` of a database named `AdventureWorks`. \n",
    "In order to gather an initial understanding of the structure of the dataframe, it can be quite useful to first look at an excerpt of the dataframe.\n",
    "\n",
    "This is possible for example with the function `print()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
        "tags": [
            "specification"
        ],
        "deletable": false,
        "editable": false
   },
   "outputs": [],
   "source": [
    "# Print the order_dataframe\n",
    "print(order_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, as you can see, this method outputs the entire content of the dataframe without any specific layout. This can cause problems, especially with very large dataframes. Therefore, it is more common to use the dataframe member function `head()`.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Task 1:</b> Use the [Pandas documentation about the function](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html) to familiarize yourself with `head()`, then apply it to the `order_dataframe` so that the first 10 tuples are displayed.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
        "tags": [
            "student"
        ],
        "deletable": false,
        "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
        "tags": [
            "solution"
        ],
        "deletable": false,
        "editable": false
   },
   "outputs": [],
   "source": [
    "# Use the head() function on the order_dataframe while setting the number of rows displayed to 10\n",
    "order_dataframe.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the representation by head() is easier to read. However, head() also has its limitations. For example, in this case we do not get all columns displayed.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Task 2:</b> All attributes of a data frame are stored in the member variable columns. Use this information to output a list (without special formatting) of all attributes contained in order_dataframe.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
       "tags": [
           "student"
       ],
       "deletable": false,
       "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
        "tags": [
            "solution"
        ],
        "deletable": false,
        "editable": false
    },
   "outputs": [],
   "source": [
    "# There are many equal solutions, e.g.:\n",
    "# Solution 1: Iterate over the columns\n",
    "for column in order_dataframe.columns:\n",
    "    print(column, end=\",\")\n",
    "    \n",
    "# Solution 2: List the columns\n",
    "# list(order_dataframe.columns)\n",
    "\n",
    "# And many more ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "TODO\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Part Two: Preprocessing - Data cleaning & Data integration\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "TODO\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Part Three: Preprocessing - Data reduction, data transformation & data discretization\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "TODO\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
