{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "specification"
    ]
   },
   "source": [
    "# 2. Data analysis & Preprocessing\n",
    "\n",
    "In this exercise you will get to know the basics from the lectures \"3. Getting to Know Your Data\" and \"4. Preprocessing\" in their practical use and apply them yourself.\n",
    "\n",
    "Since this practice sheet is designed to be used in three sessions, it is roughly divided into three sections:\n",
    "\n",
    "- [2.1. Part One: Getting to Know Your Data](#2.1. Part One: Getting to Know Your Data)\n",
    "- [2.2. Part Two: Preprocessing - Data cleaning & data integration](#2.2. Part Two: Preprocessing - Data cleaning & Data integration)\n",
    "- [2.3. Part Three: Preprocessing - Data reduction, data transformation & data discretization](#2.3. Part Three: Preprocessing - Data reduction, data transformation & data discretization)\n",
    "\n",
    "Of course, depending on how quickly an exercise group progresses in the actual exercise, one of these parts may not be discussed entirely in the affected exercise, or parts of the subsequent part may already be addressed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation: Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import tempfile\n",
    "import sqlite3\n",
    "import urllib.request\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "### Preparation: Download the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "outputs": [],
   "source": [
    "# Create a temporary directory\n",
    "dataset_folder = tempfile.mkdtemp()\n",
    "\n",
    "# Get the database\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://github.com/FAU-CS6/KDD-Databases/raw/main/AdventureWorks/adventure-works.db\",\n",
    "    dataset_folder + \"/adventure-works.db\",\n",
    ")\n",
    "\n",
    "# Open connection to the adventure-works.db\n",
    "connection = sqlite3.connect(dataset_folder + \"/adventure-works.db\")\n",
    "\n",
    "# Create the dataframe(s)\n",
    "order_dataframe = pd.read_sql_query(\n",
    "    \"SELECT * FROM Product JOIN PurchaseOrderDetail ON Product.ProductID = PurchaseOrderDetail.ProductID\",\n",
    "    connection,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "## 2.1. Part One: Getting to Know Your Data\n",
    "\n",
    "In this part you will apply the theoretical knowledge gained in the lecture \"Getting to Know Your Data\". In doing so, you will familiarize yourself step by step with the `order_dataframe` dataframe defined above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "#### 2.1.1. Structure of the Dataframe\n",
    "\n",
    "Currently you don't know anything about the `order_dataframe` except for the fact that it consists of the two tables `Product` and `PurchaseOrderDetail` of a database named `AdventureWorks`. \n",
    "In order to gather an initial understanding of the structure of the dataframe, it is useful to know the dimensions of the dataframe. The corresponding information is stored in the `shape` property of a panda dataframe.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Task 1:</b> Figure out the dimensions of order_dataframe. You are allowed to have a look at <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shape.html\">the Pandas documentation</a> regarding the mentioned property.</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "order_dataframe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "Thus, we know that the present dataframe consists of 8845 tuples and contains 34 attributes. But what we still don't know is what data is contained in the data set.\n",
    "\n",
    "In order to get a first impression in this respect, it can be useful to look at (a sample of) the data frame. The supposedly simplest method to make this possible is the `print()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "outputs": [],
   "source": [
    "# Print the order_dataframe\n",
    "print(order_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "However, as you can see, this method outputs the entire content of the dataframe without any specific layout. This can cause problems, especially with very large dataframes, and is therefore not recommended. It is far more common to use the dataframe member function `head()`.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Task 2:</b> Use the <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html\">Pandas documentation</a> to familiarize yourself with head(), then apply it to the order_dataframe so that the first 10 tuples are displayed.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Use the head() function on the order_dataframe while setting the number of rows displayed to 10\n",
    "order_dataframe.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "As you can see, the representation by head() is easier to read. However, head() also has its limitations. For example, in this case we do not get all columns displayed.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Task 3:</b> All attributes of a data frame are stored in the <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.columns.html\">member variable columns</a>. Use this information to output a list of all attributes contained in order_dataframe. No special formatting is asked, but it should be made sure that this time all column identifiers are directly named in the output.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# There are multiple possible solutions, e.g.:\n",
    "# Sample solution 1: Iterate over the columns\n",
    "for column in order_dataframe.columns:\n",
    "    print(column, end=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Sample solution 2: Use list()\n",
    "print(list(order_dataframe.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "For example, we did not see the columns \"WeightUnitMeasureCode\", \"Weight\", \"DaysToManufacture\", \"ProductLine\", \"Class\" and \"Style\" in the above execution of head().  \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Task 4:</b> Show the attributes \"WeightUnitMeasureCode\", \"Weight\", \"DaysToManufacture\", \"ProductLine\", \"Class\", \"Style\" for the first 10 tuples. (Help: <a href=\"https://pandas.pydata.org/docs/getting_started/intro_tutorials/03_subset_data.html\">Pandas tutorial on selecting subsets</a>)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# There are multiple possible solutions, e.g.:\n",
    "# Sample solution 1: Explicit naming of the identifiers\n",
    "order_dataframe[\n",
    "    [\n",
    "        \"WeightUnitMeasureCode\",\n",
    "        \"Weight\",\n",
    "        \"DaysToManufacture\",\n",
    "        \"ProductLine\",\n",
    "        \"Class\",\n",
    "        \"Style\",\n",
    "    ]\n",
    "].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Sample solution 2: Using the columns attribute\n",
    "order_dataframe[order_dataframe.columns[12:18]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "Of course, it is a pity that all the attribute values shown are `0` in the \"DaysToManufacture\" attribute and `None` in the \"ProductLine\" attribute. However, this does not mean that this is the case for the entire dataframe.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Task 5a:</b> Save all with \"DaysToManufacture\" higher than 0 into a new dataframe called order_dtm_not_zero_dataframe. (Help: <a href=\"https://pandas.pydata.org/docs/getting_started/intro_tutorials/03_subset_data.html\">Pandas tutorial on selecting subsets</a>)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Select all tuples with \"DaysToManufacture\" > 0\n",
    "order_dtm_not_zero_dataframe = order_dataframe[order_dataframe[\"DaysToManufacture\"] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Task 5b:</b> Display the columns \"WeightUnitMeasureCode\", \"Weight\", \"DaysToManufacture\", \"ProductLine\", \"Class\" and \"Style\" of the new order_dtm_not_zero_dataframe. Limit the output to 10 tuples. (Help: <a href=\"https://pandas.pydata.org/docs/getting_started/intro_tutorials/03_subset_data.html\">Pandas tutorial on selecting subsets</a>)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Do the same thing we have done in task 4\n",
    "order_dtm_not_zero_dataframe[\n",
    "    [\n",
    "        \"WeightUnitMeasureCode\",\n",
    "        \"Weight\",\n",
    "        \"DaysToManufacture\",\n",
    "        \"ProductLine\",\n",
    "        \"Class\",\n",
    "        \"Style\",\n",
    "    ]\n",
    "].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "With larger data frames, it is only possible to a limited extent to obtain an overview of all attributes. In most cases, however, this is not necessary, since the question clearly determines which attributes are more important and which are not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2. Basic Statistical Descriptors\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "TODO\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Part Two: Preprocessing - Data cleaning & Data integration\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "TODO\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Part Three: Preprocessing - Data reduction, data transformation & data discretization\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "TODO\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
