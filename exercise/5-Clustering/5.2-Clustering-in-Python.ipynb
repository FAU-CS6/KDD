{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "# 5. Clustering\n",
    "\n",
    "This JupyterNotebook is part of an exercise series titled *Clustering*.\\\n",
    "The series itself is based on lecture *8. Cluster Analysis*.\n",
    "\n",
    "This exercise series is divided into two parts. There will be one exercise session per part (= one part per week):\n",
    "\n",
    "- **5.1.** [A Close Look at K-Means and DBSCAN](./5.1-A-Close-Look-at-K-Means-and-DBSCAN.ipynb) (*last weeks notebook*)\n",
    "- **5.2.** Clustering in Python (*this notebook*)\n",
    "    - **5.2.1.** [Clustering Products Based on their Profitability](#5.2.1.-Clustering-Products-Based-on-their-Profitability)\n",
    "    - **5.2.2.** [Clustering Customers Based on their Interests](#5.2.2.-Clustering-Customers-Based-on-their-Interests)\n",
    "        - **5.2.2.1.** [Clustering](#5.2.2.1.-Clustering)\n",
    "        - **5.2.2.2.** [Validation](#5.2.2.2.-Validation)\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "**Important:**\n",
    "    \n",
    "Work on the respective part yourself **BEFORE** each exercise session. The exercise session is **NOT** intended to take a first look at the exercise sheet, but to solve problems students had while preparing the exercise sheet beforehand.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "## 5.2. Clustering in Python\n",
    "\n",
    "After implementing K-means and DBSCAN in [**5.1.**](./5.1-A-Close-Look-at-K-Means-and-DBSCAN.ipynb), in this part you get to try out your knowledge of clustering methods with the AdventureWorks database. \n",
    "\n",
    "For this purpose, you will be presented with two fictitious scenarios, which you may work on either completely independently or guided:\n",
    "\n",
    "   - **5.2.1.** [Clustering Products Based on their Profitability](#5.2.1.-Clustering-Products-Based-on-their-Profitability)\n",
    "   - **5.2.2.** [Clustering Customers Based on their Interests](#5.2.2.-Clustering-Customers-Based-on-their-Interests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import tempfile\n",
    "import sqlite3\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "outputs": [],
   "source": [
    "# Create a temporary directory\n",
    "dataset_folder = tempfile.mkdtemp()\n",
    "\n",
    "# Build path to database\n",
    "database_path = os.path.join(dataset_folder, \"adventure-works.db\")\n",
    "\n",
    "# Get the database\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://github.com/FAU-CS6/KDD-Databases/raw/main/AdventureWorks/adventure-works.db\",\n",
    "    database_path,\n",
    ")\n",
    "\n",
    "# Open connection to the adventure-works.db\n",
    "connection = sqlite3.connect(database_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "### 5.2.1. Clustering Products Based on their Profitability\n",
    "\n",
    "The first scenario is intended to first look at clustering in practice without major stumbling blocks. For this purpose, you are to put yourself in the following scenario:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "*You are once again a Data Scientist at the fictitious company Adventure Works GmbH. After your successful analyses on the topic of Frequent Patterns, your bosses now assign you the task of dividing the products into groups of different profitability.*\n",
    "\n",
    "*In discussions with your business administration colleagues, you learn that the decisive metrics here are probably the number of products actually sold and the profit per product (the sales price minus the production costs).*\n",
    "\n",
    "*The colleagues from IT tell you that you will probably find the required data in the tables `Product` and `SalesOrderDetail`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "You are now given two options:\n",
    "\n",
    "You can either do the assignment on your own or try a step-by-step guided version.\n",
    "\n",
    "- **Option 1:** [Cluster the Products on your Own](#Option-1:-Cluster-the-Products-on-your-Own)\n",
    "- **Option 2:** [Cluster the Products using Step-by-Step Tasks](#Option-2:-Cluster-the-Products-using-Step-by-Step-Tasks)\n",
    "\n",
    "We recommend that you first try it on your own and only switch to the guided version if you encounter problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "#### Option 1: Cluster the Products on your Own\n",
    "\n",
    "You may, of course, once again set about the task without help. Be aware that the two values suggested by your colleagues may not be available in the required form at the beginning. Also, think about which clustering method is best suited for the tasks.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 1.1:** \n",
    "    \n",
    "Group the products within the OLTP database of the fictitious Adventure Works GmbH according to their profitability. Furthermore, visualize the result.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Cluster the products based on their profitability (Code placeholder 01/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Cluster the products based on their profitability (Code placeholder 02/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster the products based on their profitability (Code placeholder 03/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Cluster the products based on their profitability (Code placeholder 04/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Cluster the products based on their profitability (Code placeholder 05/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Cluster the products based on their profitability (Code placeholder 06/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Cluster the products based on their profitability (Code placeholder 07/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Cluster the products based on their profitability (Code placeholder 08/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Cluster the products based on their profitability (Code placeholder 09/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Cluster the products based on their profitability (Code placeholder 10/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Sample solution => See Option 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "#### Option 2: Cluster the Products using Step-by-Step Tasks \n",
    "\n",
    "A first step in any KDD Task should always be to get a look at the available data. In this case we already know which tables may be relevant for us: `Product` and `SalesOrderDetail`.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 1.2.1:**\n",
    "    \n",
    "Load the relations `Product` and `SalesOrderDetail` into two individual DataFrames and display the first ten rows of each DataFrame.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Load Product into a DataFrame and display the first ten rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Load SalesOrderDetail into a DataFrame and display the first ten rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Load Product into a DataFrame and display the first ten rows\n",
    "product_df = pd.read_sql_query(\"SELECT * FROM Product\", connection)\n",
    "product_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Load SalesOrderDetail into a DataFrame and display the first ten rows\n",
    "sales_order_detail_df = pd.read_sql_query(\"SELECT * FROM SalesOrderDetail\", connection)\n",
    "sales_order_detail_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "It can be seen that the attribute 'ProductID' is probably the link between the two tables. It is less clear how to calculate the two metrics suggested by the business colleagues.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 1.2.2:** \n",
    "    \n",
    "Consider which attributes are needed for the two proposed metrics and how to combine them. Do not worry about the implementation in SQL/Python at this moment.\n",
    "If you do not yet know everything about the data sets that you need to accomplish this task, try to learn more about the data sets.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "source": [
    "How to compute the metrics required for the clustering:\n",
    "\n",
    "- **Number of copies sold per product:**  \n",
    "Write down your solution here\n",
    "- **Average profit per copy sold (per product):**  \n",
    "Write down your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "How to compute the metrics required for the clustering:\n",
    "\n",
    "- **Number of copies sold per product:**  \n",
    "The table `SalesOrderDetail` contains information on how many products have been sold within that single order (`OrderQty`). If we sum up the `OrderQty` per product we get the number of copies sold per product.\n",
    "- **Average profit per copy sold (per product):**  \n",
    "First of all, it must be understood that the profit per sale can be calculated simply by subtracting the manufacturing cost (`StandardCost` in `Product`) from the actual selling price (`UnitPrice` in `SalesOrderDetail`). In this case, however, should not be summed up for a product, but the average should be determined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 1.2.3:** \n",
    "    \n",
    "Calculate both values (`ProfitPerUnit` and `OverallOrderQty`) and generate a corresponding DataFrame `product_overview_df` containing the `ProductID` as well as the `ProfitPerUnit` and the `OverallOrderQty`. You may use SQL and/or Python to perform the computation.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Load `ProductID`,`ProfitPerUnit` and `OverallOrderQty` into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Load `ProductID`,`ProfitPerUnit` and `OverallOrderQty` into a DataFrame\n",
    "product_overview_df = pd.read_sql_query(\n",
    "    \"SELECT p.ProductID, AVG(sod.UnitPrice - p.StandardCost) AS ProfitPerUnit, SUM(sod.OrderQty) AS OverallOrderQty FROM Product p, SalesOrderDetail sod WHERE p.ProductID = sod.ProductID GROUP BY p.ProductID\",\n",
    "    connection,\n",
    ")\n",
    "product_overview_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "Since the value range of `OverallOrderQty` goes from 4 to 8311 and the value range of `ProfitPerUnit` only goes from about -55 to about 1155, this dataset would not currently be a good fit for most clustering techniques. The `OverallOrderQty` would have a much higher influence in this case, which is why it makes sense to normalize the `product_overview_df` first. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 1.2.4:**\n",
    "    \n",
    "Normalize the `product_overview_df`. You may write your own function or use a library for this. Already imported is the `MinMaxScaler` from scikit-learn.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Normalize the product_overview_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Normalize the product_overview_df\n",
    "min_max_scaler = MinMaxScaler()\n",
    "product_overview_df[\n",
    "    [\"ProfitPerUnit\", \"OverallOrderQty\"]\n",
    "] = min_max_scaler.fit_transform(\n",
    "    product_overview_df[[\"ProfitPerUnit\", \"OverallOrderQty\"]]\n",
    ")\n",
    "product_overview_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "The now generated DataFrame can be used well for clustering. However, the question is which clustering method should be used. We will focus on K-Means, DBSCAN and BIRCH. All of these methods have been presented in the lecture and are implemented in scikit-learn. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 1.2.5:**\n",
    "    \n",
    "Run scikit-learn's K-means for the DataFrame at hand. You have to determine a good number of clusters yourself. Visualize the results as known from Part One.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Perform scikit-learn's K-means clustering on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Perform scikit-learn's K-means clustering on the dataset\n",
    "kmeans = KMeans(n_clusters=6, n_init=\"auto\").fit(\n",
    "    product_overview_df[[\"ProfitPerUnit\", \"OverallOrderQty\"]]\n",
    ")\n",
    "\n",
    "# Save the labels to a copy of the big_dataset to generate the equivalent of our clustered_big_dataset\n",
    "clustered_product_overview_df = product_overview_df.copy()\n",
    "clustered_product_overview_df[\"cluster\"] = kmeans.labels_\n",
    "\n",
    "# Print the result\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.scatterplot(\n",
    "    x=clustered_product_overview_df[\"ProfitPerUnit\"],\n",
    "    y=clustered_product_overview_df[\"OverallOrderQty\"],\n",
    "    hue=clustered_product_overview_df[\"cluster\"],\n",
    "    palette=\"deep\",\n",
    ")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 1.2.6:**\n",
    "    \n",
    "Run scikit-learn's DBSCAN for the DataFrame at hand. You have to determine a good number of clusters yourself. Visualize the results as known from Part One.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Perform scikit-learn's DBSCAN clustering on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Perform scikit-learn's DBSCAN clustering on the dataset\n",
    "dbscan = DBSCAN(eps=0.2, min_samples=5).fit(\n",
    "    product_overview_df[[\"ProfitPerUnit\", \"OverallOrderQty\"]]\n",
    ")\n",
    "\n",
    "# Save the labels to a copy of the big_dataset to generate the equivalent of our clustered_big_dataset\n",
    "clustered_product_overview_df = product_overview_df.copy()\n",
    "clustered_product_overview_df[\"cluster\"] = dbscan.labels_\n",
    "\n",
    "# Print the result\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.scatterplot(\n",
    "    x=clustered_product_overview_df[\"ProfitPerUnit\"],\n",
    "    y=clustered_product_overview_df[\"OverallOrderQty\"],\n",
    "    hue=clustered_product_overview_df[\"cluster\"],\n",
    "    palette=\"deep\",\n",
    ")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 1.2.7:**\n",
    "    \n",
    "Run scikit-learn's BIRCH for the DataFrame at hand. You have to determine a good number of clusters yourself. Visualize the results as known from Part One.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Perform scikit-learn's BIRCH clustering on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Perform scikit-learn's BIRCH clustering on the dataset\n",
    "birch = Birch(threshold=0.1, n_clusters=6).fit(\n",
    "    product_overview_df[[\"ProfitPerUnit\", \"OverallOrderQty\"]]\n",
    ")\n",
    "\n",
    "# Save the labels to a copy of the big_dataset to generate the equivalent of our clustered_big_dataset\n",
    "clustered_product_overview_df = product_overview_df.copy()\n",
    "clustered_product_overview_df[\"cluster\"] = birch.labels_\n",
    "\n",
    "# Print the result\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.scatterplot(\n",
    "    x=clustered_product_overview_df[\"ProfitPerUnit\"],\n",
    "    y=clustered_product_overview_df[\"OverallOrderQty\"],\n",
    "    hue=clustered_product_overview_df[\"cluster\"],\n",
    "    palette=\"deep\",\n",
    ")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "Of course, your fictitious bosses don't want to be presented with three different results from you. A clustering procedure should be chosen. For this purpose, it is useful to compare the results briefly.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 1.2.8:**\n",
    "    \n",
    "Compare the results you have achieved with all three methods and consider which one you think is best.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "source": [
    "Write down your solution here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "Of course, this comparison also depends on the results you were able to achieve through optimization of parameters. However some things should be unversally valid:\n",
    "\n",
    "- **K-means and BIRCH:**  \n",
    "Both K-means and BIRCH produce quite similar results in this case. With our parameters we can interpret the found clusters the following way: \n",
    "  - Less interesting from a business perspective:\n",
    "    - The cluster that does not bring much profit per unit and that was not sold frequently.\n",
    "    - The cluster that does not bring much profit per unit, but was sold at least a little more often.\n",
    "    - The cluster that brings a little more profit per unit, but which was not sold frequently.\n",
    "  - Interesting from a business perspective:\n",
    "    - The cluster that does not bring much profit per unit, but which was sold at least extremely often.\n",
    "    - The cluster that is average both in terms of profit per unit and frequency of sales.\n",
    "    - The cluster that brings extremely much profit, but which was hardly sold.\n",
    "\n",
    "- **DBSCAN:**  \n",
    "With our parameters we can interpret the found clusters the following way:\n",
    "  - Less interesting from a business perspective:\n",
    "    - Merged into one cluster\n",
    "  - Interesting from a business perspective:\n",
    "    - The cluster that does not bring much profit per unit, but which was sold at least extremely often.\n",
    "    - The cluster that is average both in terms of profit per unit and frequency of sales.\n",
    "    - The cluster that brings extremely much profit, but which was hardly sold.\n",
    "    \n",
    "Since DBSCAN merges the less interesting products into a cluster, it can be said that DBSCAN is probably the better choice here. This way, the focus in a presentation can be placed on the economically more interesting product clusters. \n",
    "\n",
    "However, it is of course not a big problem in this case if K-means or BIRCH are used, since one can at least argue that here a better distinction is made between completely uninteresting and at least somewhat interesting products."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "### 5.2.2. Clustering Customers Based on their Interests\n",
    "\n",
    "The first scenario was quite straightforward. Before we briefly look at why this is not the case with the second scenario, we must first introduce it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "*As a Data Scientist who has already solved two different tasks for his bosses in the fictitious Adventure Works GmbH, you are immediately assigned another task. Your bosses want to make the sales team more efficient by assigning customers with similar product interests to the same employee.*\n",
    "\n",
    "*In order to be able to carry out this reassignment, you are tasked with dividing the customers into 16 clusters (there are 16 sales persons in the company). This classification is to be based on the products that the customers have ordered in the past.*\n",
    "\n",
    "*Via the IT department you learn that the customers can probably be found in the table ´Customer´. You will need to join the table `SalesOrderHeader` and then the table `SalesOrderDetail` to get information on the ordered ProductIDs per customers.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "But before you can dive into the task on your own or with help, we first need to take a look at the relevant dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "outputs": [],
   "source": [
    "customer_purchases_df = pd.read_sql_query(\n",
    "    \"SELECT c.CustomerID, sod.ProductID, sod.OrderQty FROM Customer c JOIN SalesOrderHeader soh ON c.CustomerID = soh.CustomerID JOIN SalesOrderDetail sod ON sod.SalesOrderID = soh.SalesOrderID\",\n",
    "    connection,\n",
    "    index_col=\"CustomerID\",\n",
    ")\n",
    "customer_purchases_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "If the attribute `ProductID` were fed directly to the clustering in this form, simply the numerical distance between two product IDs would be used to calculate a distance between customers. \n",
    "\n",
    "A customer who bought only the product with ID `707` would thus be more dissimilar to a customer who bought only the product with ID `879` than to a customer who bought only the product with ID `712`. Usually, however, the distribution of product IDs is not based on similarity, but simply on the order in which the products were added to the catalog.\n",
    "\n",
    "So for this task, we first need to put the data into a different format. Basically, we need to compare each customer's interest in each product individually. That means we need one dimension per product.\n",
    "\n",
    "But here, too, we have to choose between two different possibilities:\n",
    "\n",
    "- **Concept 1:** Determine for each product if the customer has purchased the product (binary scale):\n",
    "\n",
    "|            | Product 1 | Product 2 | Product 3 | Product 4 |\n",
    "|------------|-----------|-----------|-----------|-----------|\n",
    "| Customer 1 | 1         | 0         | 0         | 0         |\n",
    "| Customer 2 | 1         | 1         | 0         | 0         |\n",
    "| Customer 3 | 0         | 1         | 1         | 1         |\n",
    "\n",
    "\n",
    "- **Concept 2:** Determine sum of copies purchased for each product purchased (continous scale): \n",
    "\n",
    "|            | Product 1 | Product 2 | Product 3 | Product 4 |\n",
    "|------------|-----------|-----------|-----------|-----------|\n",
    "| Customer 1 | 236       | 0         | 0         | 0         |\n",
    "| Customer 2 | 1         | 199       | 0         | 0         |\n",
    "| Customer 3 | 0         | 199       | 5         | 1         |\n",
    "\n",
    "In the first variant, `Customer 1` and `Customer 2` would be most similar. In the second variant, the interests of `Customer 2` and `Customer 3` would be most similar.\n",
    "\n",
    "Since both options have pros and cons in your case, you decide to discuss the two options with your superiors:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "*When you present the two options to your supervisors, they decide that the number of copies purchased should be relevant in determining similar interests. One of the supervisors justifies this decision as follows:*\n",
    "\n",
    "*In the example, each of the customers obviously has more interest in certain products. A sales person who looks after `Customer 1` and `Customer 2` would be responsible for large orders for `Product 1` and `Product 2` and would therefore have to be well versed in both products. While a common sales person for `Customer 2` and `Customer 3` would only need to be expert in `Product 2`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "#### 5.2.2.1. Clustering\n",
    "\n",
    "You are now given two options:\n",
    "\n",
    "You can either do the assignment on your own or try a step-by-step guided version.\n",
    "\n",
    "- **Option 1:** [Cluster the Customers on your Own](#Option-1:-Cluster-the-Customers-on-your-Own)\n",
    "- **Option 2:** [Cluster the Customers using Step-by-Step Tasks](#Option-2:-Cluster-the-Customers-using-Step-by-Step-Tasks)\n",
    "\n",
    "We recommend that you first try it on your own and only switch to the guided version if you encounter problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "##### Option 1: Cluster the Customers on your Own\n",
    "\n",
    "Now that you are prepared for the one of the stumbling blocks in this task, you are again free to tackle it on your own. Since more than two dimensions are relevant this time, no visualization is necessary. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 2.1:**\n",
    "    \n",
    "Group the customers into 16 clusters by using K-means. You do not need to visualize the result.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Cluster the customers based on their interests (Code placeholder 01/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Cluster the customers based on their interests (Code placeholder 02/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Cluster the customers based on their interests (Code placeholder 03/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Cluster the customers based on their interests (Code placeholder 04/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Cluster the customers based on their interests (Code placeholder 05/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Cluster the customers based on their interests (Code placeholder 06/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Cluster the customers based on their interests (Code placeholder 07/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Cluster the customers based on their interests (Code placeholder 08/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Cluster the customers based on their interests (Code placeholder 09/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Cluster the customers based on their interests (Code placeholder 10/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Sample solution => See Option 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "##### Option 2: Cluster the Customers using Step-by-Step Tasks\n",
    "\n",
    "Having already considered the data set during the explanation of the issues with this task, we do not propose a mandatory \"Getting to Know Your Data\" task at this point. However, we do recommend that you continue to familiarize yourself with the dataset at hand if you still see ambiguities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "outputs": [],
   "source": [
    "# Placeholder for optional \"Getting to Know Your Data\" code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "The first step on the way to clustering, is to load a DataFrame from the database, in which the sum of all purchased copies per customer and product is listed.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 2.2.1:**\n",
    "    \n",
    "Load a DataFrame that contains the total copies (`TotalOrderQty`) purchased per customer and product.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Load a DataFrame that contains the total copies purchased per customer and product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Load a DataFrame that contains the total copies purchased per customer and product\n",
    "customer_interests_df = pd.read_sql_query(\n",
    "    \"SELECT c.CustomerID, sod.ProductID, SUM(sod.OrderQty) AS TotalOrderQty FROM Customer c JOIN SalesOrderHeader soh ON c.CustomerID = soh.CustomerID JOIN SalesOrderDetail sod ON sod.SalesOrderID = soh.SalesOrderID GROUP BY c.CustomerID, sod.ProductID\",\n",
    "    connection,\n",
    ")\n",
    "customer_interests_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "We can now pivot this DataFrame so that the `CustomerID` forms the index of the rows, the `ProductID` the columns and the `TotalOrderQty`. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 2.2.2:**\n",
    "    \n",
    "Use `pivot` to bring the DataFrame into the correct format. Replace created `NaN` values with `0`s. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Pivot the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Pivot the DataFrame\n",
    "customer_interests_pivot_df = customer_interests_df.pivot(\n",
    "    index=\"CustomerID\", columns=\"ProductID\", values=\"TotalOrderQty\"\n",
    ").fillna(0)\n",
    "customer_interests_pivot_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "This DataFrame is now prepared to be used in clustering. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 2.2.3:**\n",
    "    \n",
    "Use the K-means implementation of scikit-learn to cluster the DataFrame into 16 clusters.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Perform scikit-learn's K-means clustering on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Perform scikit-learn's K-means clustering on the dataset\n",
    "kmeans = KMeans(n_clusters=16, n_init=\"auto\").fit(customer_interests_pivot_df)\n",
    "\n",
    "# Save the labels to a copy of the big_dataset to generate the equivalent of our clustered_big_dataset\n",
    "clustered_customer_interests_pivot_df = customer_interests_pivot_df.copy()\n",
    "clustered_customer_interests_pivot_df[\"cluster\"] = kmeans.labels_\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "clustered_customer_interests_pivot_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "#### 5.2.2.2. Validation\n",
    "\n",
    "Now that we have 16 clusters, one might assume that the task has been solved. However, there is another stumbling block in this task.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 3:**\n",
    "    \n",
    "Output how many customers are in each of the clusters.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Get the count of customers per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Get the count of customers per cluster\n",
    "clustered_customer_interests_pivot_df[[\"cluster\"]].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "A very unbalanced distribution can be seen, indicating that these clusters should definitely not be used in this way to assign customers to the 16 sales persons. If you try the different clustering methods implemented scikit-learn, you will notice that none of the methods changes this imbalance decisively. \n",
    "\n",
    "This is simply because clustering is not designed to achieve (roughly) equal cluster sizes. There are ideas here on how to get around this (e.g., calculate significantly more clusters and then merge each of these with neighbors until about the required size is reached), but these new groups would then not necessarily only contain customers with similar interests. \n",
    "\n",
    "It would make more sense here to approach the fictitious bosses again and tell them that similarity of interests is probably not the best criterion for dividing customers among sales persons. \n",
    "\n",
    "Since it is of course a shame to end an exercise sheet with a perceived failure: \n",
    "There are some interesting things that can be concluded from the identified clusters. We now know that the majority of the customer base seems to share similar interests. This can be pitched to the manangement to further specialize the focus of the company. Even failures in data science sometimes contain new insights, you just have to be open enough to discover them."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
