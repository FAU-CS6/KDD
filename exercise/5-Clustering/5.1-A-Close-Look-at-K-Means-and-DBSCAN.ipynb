{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "# 5. Clustering\n",
    "\n",
    "This JupyterNotebook is part of an exercise series titled *Clustering*.\\\n",
    "The series itself is based on lecture *8. Cluster Analysis*.\n",
    "\n",
    "This exercise series is divided into two parts. There will be one exercise session per part (= one part per week):\n",
    "\n",
    "- **5.1.** A Close Look at K-Means and DBSCAN (*this notebook*)\n",
    "    - **5.1.1.** [K-Means](#5.1.1.-K-Means)\n",
    "        - **5.1.1.1.** [Application by Hand](#5.1.1.1.-Application-by-Hand)\n",
    "        - **5.1.1.2.** [Implementation](#5.1.1.2.-Implementation)\n",
    "        - **5.1.1.3.** [K-Means in scikit-learn](#5.1.1.3.-K-Means-in-scikit-learn)\n",
    "    - **5.1.2.** [DBSCAN](#5.1.2.-DBSCAN)\n",
    "        - **5.1.2.1.** [Basic Terms](#5.1.2.1.-Basic-Terms)\n",
    "            - **5.1.2.1.1.** [Core Point](#5.1.2.1.1.-Core-Point)\n",
    "            - **5.1.2.1.2.** [Directly Density-Reachable](#5.1.2.1.2.-Directly-Density-Reachable)\n",
    "            - **5.1.2.1.3.** [Density-Reachable](#5.1.2.1.3.-Density-Reachable)\n",
    "            - **5.1.2.1.4.** [Density-Connected](#5.1.2.1.4.-Density-Connected)\n",
    "        - **5.1.2.2.** [Application by Hand](#5.1.2.2.-Application-by-Hand)\n",
    "        - **5.1.2.3.** [Implementation](#5.1.2.3.-Implementation)\n",
    "        - **5.1.2.4.** [DBSCAN in scikit-learn](#5.1.2.4.-DBSCAN-in-scikit-learn)\n",
    "- **5.2.** [Clustering in Python](./5.2-Clustering-in-Python.ipynb) (*next weeks notebook*)\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "**Important:**\n",
    "    \n",
    "Work on the respective part yourself **BEFORE** each exercise session. The exercise session is **NOT** intended to take a first look at the exercise sheet, but to solve problems students had while preparing the exercise sheet beforehand.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "## 5.1. A Close Look at K-Means and DBSCAN\n",
    "\n",
    "In this part we will take a closer look at two clustering methods known from the lecture: K-means and DBSCAN. \n",
    "\n",
    "In the following, you will first apply both methods step by step by hand to a data set and then write your own implementation for both methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import math\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "The data set to cluster is the same for both methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "dataset = pd.DataFrame(\n",
    "    [\n",
    "        [1, 1],\n",
    "        [1, 2],\n",
    "        [1, 4],\n",
    "        [2, 1],\n",
    "        [2, 3],\n",
    "        [3, 2],\n",
    "        [3, 4],\n",
    "        [4, 1],\n",
    "        [4, 3],\n",
    "        [4, 4],\n",
    "    ],\n",
    "    columns=[\"x\", \"y\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "### 5.1.1. K-Means\n",
    "\n",
    "The first clustering method we are taking a close look at is K-means. It is part of the partitioning methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "#### 5.1.1.1. Application by Hand\n",
    "\n",
    "In order to familiarise yourself with K-means, you should first apply K-means by hand.\n",
    "\n",
    "Given is the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "outputs": [],
   "source": [
    "# Output the dataset\n",
    "fig = plt.figure(figsize=(9, 4))\n",
    "\n",
    "# As a scatterplot\n",
    "scat = fig.add_subplot(121)\n",
    "scat.scatter(x=dataset[\"x\"], y=dataset[\"y\"])\n",
    "\n",
    "# As a table\n",
    "data = fig.add_subplot(122)\n",
    "data.axis(\"off\")\n",
    "data.table(\n",
    "    cellText=dataset.values,\n",
    "    rowLabels=dataset.index,\n",
    "    bbox=[0, 0, 1, 1],\n",
    "    colLabels=dataset.columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "You are now to apply K-Means to this data set by hand. We will use the Euclidean distance and a k of three in both cases:\n",
    "\n",
    "- **Option 1:** [Apply K-Means on your own](#Option-1:-Apply-K-Means-on-your-own)\n",
    "- **Option 2:** [Apply K-Means step by step](#Option-2:-Apply-K-Means-step-by-step)\n",
    "\n",
    "It is recommended that you first try it on your own and only resort to the guided step-by-step variant if you have problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "##### Option 1: Apply K-Means on your own\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 1.1:** \n",
    "    \n",
    "Use K-Means to cluster the data points into three clusters. Write down all intermediate steps.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "source": [
    "Write down your solution here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "Sample solution => See Option 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "##### Option 2: Apply K-Means step by step\n",
    "\n",
    "The first step of K-Means is to arbitrarily distribute all data points into k partitions. This can be done in many different ways (e.g. randomly or by dividing the points into partitions of equal size).\n",
    "\n",
    "In this case we distribute the points into (approximately) equal-sized partitions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "| x | y | Partition |\n",
    "|:-:|:-:|:---------:|\n",
    "| 1 | 1 |     1     |\n",
    "| 1 | 2 |     1     |\n",
    "| 1 | 4 |     1     |\n",
    "| 2 | 1 |     1     |\n",
    "| 2 | 3 |     2     |\n",
    "| 3 | 2 |     2     |\n",
    "| 3 | 4 |     2     |\n",
    "| 4 | 1 |     3     |\n",
    "| 4 | 3 |     3     |\n",
    "| 4 | 4 |     3     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "The next step is to calculate the centroids of the partitions.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 1.2.1:** \n",
    "    \n",
    "Determine the coordinates of the centroids of the partitions.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "source": [
    "Write down your solution here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "**Centroid of Partition 1:**\n",
    "\n",
    "- $x = \\frac{1 + 1 + 1 + 2}{4} = 1,25$\n",
    "- $y = \\frac{1 + 2 + 4 + 1}{4} = 2$\n",
    "\n",
    "**Centroid of Partition 2:**\n",
    "\n",
    "- $x = \\frac{2 + 3 + 3}{3} = \\frac{8}{3} \\approx 2,667$\n",
    "- $y = \\frac{3 + 2 + 4}{3} = 3$ \n",
    "\n",
    "**Centroid of Partition 3:**\n",
    "\n",
    "- $x = \\frac{4 + 4 + 4}{3} = 4$\n",
    "- $y = \\frac{1 + 3 + 4}{3} = \\frac{8}{3} \\approx 2,667$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "Next, the nearest centroid is calculated for each of the original data points. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 1.2.2:** \n",
    "    \n",
    "For each data point, determine which centroid has the smallest Euclidean distance to that point.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "source": [
    "Write down your solution here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "**Data Point at (1,1):**\n",
    "- $Distance_{(1,1)\\leftrightarrow(1.25,2.0)} = \\sqrt{(1-1.25)^2+(1-2.0)^2} \\approx 1.03$\n",
    "- $Distance_{(1,1)\\leftrightarrow(2.67,3.0)} = \\sqrt{(1-2.67)^2+(1-3.0)^2} \\approx 2.6$\n",
    "- $Distance_{(1,1)\\leftrightarrow(4.0,2.67)} = \\sqrt{(1-4.0)^2+(1-2.67)^2} \\approx 3.43$\n",
    " \n",
    "Nearest centroid: $(1.25,2.0)$ (Partition 1)\n",
    " \n",
    "**Data Point at (1,2):**\n",
    "- $Distance_{(1,2)\\leftrightarrow(1.25,2.0)} = \\sqrt{(1-1.25)^2+(2-2.0)^2} \\approx 0.25$\n",
    "- $Distance_{(1,2)\\leftrightarrow(2.67,3.0)} = \\sqrt{(1-2.67)^2+(2-3.0)^2} \\approx 1.94$\n",
    "- $Distance_{(1,2)\\leftrightarrow(4.0,2.67)} = \\sqrt{(1-4.0)^2+(2-2.67)^2} \\approx 3.07$\n",
    " \n",
    "Nearest centroid: $(1.25,2.0)$ (Partition 1)\n",
    " \n",
    "**Data Point at (1,4):**\n",
    "- $Distance_{(1,4)\\leftrightarrow(1.25,2.0)} = \\sqrt{(1-1.25)^2+(4-2.0)^2} \\approx 2.02$\n",
    "- $Distance_{(1,4)\\leftrightarrow(2.67,3.0)} = \\sqrt{(1-2.67)^2+(4-3.0)^2} \\approx 1.94$\n",
    "- $Distance_{(1,4)\\leftrightarrow(4.0,2.67)} = \\sqrt{(1-4.0)^2+(4-2.67)^2} \\approx 3.28$\n",
    " \n",
    "Nearest centroid: $(2.67,3.0)$ (Partition 2)\n",
    " \n",
    "**Data Point at (2,1):**\n",
    "- $Distance_{(2,1)\\leftrightarrow(1.25,2.0)} = \\sqrt{(2-1.25)^2+(1-2.0)^2} \\approx 1.25$\n",
    "- $Distance_{(2,1)\\leftrightarrow(2.67,3.0)} = \\sqrt{(2-2.67)^2+(1-3.0)^2} \\approx 2.11$\n",
    "- $Distance_{(2,1)\\leftrightarrow(4.0,2.67)} = \\sqrt{(2-4.0)^2+(1-2.67)^2} \\approx 2.6$\n",
    " \n",
    "Nearest centroid: $(1.25,2.0)$ (Partition 1)\n",
    " \n",
    "**Data Point at (2,3):**\n",
    "- $Distance_{(2,3)\\leftrightarrow(1.25,2.0)} = \\sqrt{(2-1.25)^2+(3-2.0)^2} \\approx 1.25$\n",
    "- $Distance_{(2,3)\\leftrightarrow(2.67,3.0)} = \\sqrt{(2-2.67)^2+(3-3.0)^2} \\approx 0.67$\n",
    "- $Distance_{(2,3)\\leftrightarrow(4.0,2.67)} = \\sqrt{(2-4.0)^2+(3-2.67)^2} \\approx 2.03$\n",
    " \n",
    "Nearest centroid: $(2.67,3.0)$ (Partition 2)\n",
    " \n",
    "**Data Point at (3,2):**\n",
    "- $Distance_{(3,2)\\leftrightarrow(1.25,2.0)} = \\sqrt{(3-1.25)^2+(2-2.0)^2} \\approx 1.75$\n",
    "- $Distance_{(3,2)\\leftrightarrow(2.67,3.0)} = \\sqrt{(3-2.67)^2+(2-3.0)^2} \\approx 1.05$\n",
    "- $Distance_{(3,2)\\leftrightarrow(4.0,2.67)} = \\sqrt{(3-4.0)^2+(2-2.67)^2} \\approx 1.2$\n",
    " \n",
    "Nearest centroid: $(2.67,3.0)$ (Partition 2)\n",
    " \n",
    "**Data Point at (3,4):**\n",
    "- $Distance_{(3,4)\\leftrightarrow(1.25,2.0)} = \\sqrt{(3-1.25)^2+(4-2.0)^2} \\approx 2.66$\n",
    "- $Distance_{(3,4)\\leftrightarrow(2.67,3.0)} = \\sqrt{(3-2.67)^2+(4-3.0)^2} \\approx 1.05$\n",
    "- $Distance_{(3,4)\\leftrightarrow(4.0,2.67)} = \\sqrt{(3-4.0)^2+(4-2.67)^2} \\approx 1.67$\n",
    " \n",
    "Nearest centroid: $(2.67,3.0)$ (Partition 2)\n",
    " \n",
    "**Data Point at (4,1):**\n",
    "- $Distance_{(4,1)\\leftrightarrow(1.25,2.0)} = \\sqrt{(4-1.25)^2+(1-2.0)^2} \\approx 2.93$\n",
    "- $Distance_{(4,1)\\leftrightarrow(2.67,3.0)} = \\sqrt{(4-2.67)^2+(1-3.0)^2} \\approx 2.4$\n",
    "- $Distance_{(4,1)\\leftrightarrow(4.0,2.67)} = \\sqrt{(4-4.0)^2+(1-2.67)^2} \\approx 1.67$\n",
    " \n",
    "Nearest centroid: $(4.0,2.67)$ (Partition 3)\n",
    " \n",
    "**Data Point at (4,3):**\n",
    "- $Distance_{(4,3)\\leftrightarrow(1.25,2.0)} = \\sqrt{(4-1.25)^2+(3-2.0)^2} \\approx 2.93$\n",
    "- $Distance_{(4,3)\\leftrightarrow(2.67,3.0)} = \\sqrt{(4-2.67)^2+(3-3.0)^2} \\approx 1.33$\n",
    "- $Distance_{(4,3)\\leftrightarrow(4.0,2.67)} = \\sqrt{(4-4.0)^2+(3-2.67)^2} \\approx 0.33$\n",
    " \n",
    "Nearest centroid: $(4.0,2.67)$ (Partition 3)\n",
    " \n",
    "**Data Point at (4,4):**\n",
    "- $Distance_{(4,4)\\leftrightarrow(1.25,2.0)} = \\sqrt{(4-1.25)^2+(4-2.0)^2} \\approx 3.4$\n",
    "- $Distance_{(4,4)\\leftrightarrow(2.67,3.0)} = \\sqrt{(4-2.67)^2+(4-3.0)^2} \\approx 1.67$\n",
    "- $Distance_{(4,4)\\leftrightarrow(4.0,2.67)} = \\sqrt{(4-4.0)^2+(4-2.67)^2} \\approx 1.33$\n",
    " \n",
    "Nearest centroid: $(4.0,2.67)$ (Partition 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "In the next step, the data points are assigned to the partition to which the respective centroid belongs.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 1.2.3:** \n",
    "    \n",
    "Assign the points to the respective new partition.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "source": [
    "| x | y | Old Partition | New Partition |\n",
    "|:-:|:-:|:-------------:|:-------------:|\n",
    "| 1 | 1 |       1       |       ?       |\n",
    "| 1 | 2 |       1       |       ?       |\n",
    "| 1 | 4 |       1       |       ?       |\n",
    "| 2 | 1 |       1       |       ?       |\n",
    "| 2 | 3 |       2       |       ?       |\n",
    "| 3 | 2 |       2       |       ?       |\n",
    "| 3 | 4 |       2       |       ?       |\n",
    "| 4 | 1 |       3       |       ?       |\n",
    "| 4 | 3 |       3       |       ?       |\n",
    "| 4 | 4 |       3       |       ?       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "| x | y | Old Partition | New Partition |\n",
    "|:-:|:-:|:-------------:|:-------------:|\n",
    "| 1 | 1 |       1       |       1       |\n",
    "| 1 | 2 |       1       |       1       |\n",
    "| 1 | 4 |       1       |       2       |\n",
    "| 2 | 1 |       1       |       1       |\n",
    "| 2 | 3 |       2       |       2       |\n",
    "| 3 | 2 |       2       |       2       |\n",
    "| 3 | 4 |       2       |       2       |\n",
    "| 4 | 1 |       3       |       3       |\n",
    "| 4 | 3 |       3       |       3       |\n",
    "| 4 | 4 |       3       |       3       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "Since a point has been assigned into a new partition, a new run begins in which centroids are determined, the distances of the points to the new centroids are measured and a reallocation of points takes place. This takes place until there are no more partition changes.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 1.2.4:**\n",
    "    \n",
    "Continue K-means until no points are reassigned.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "source": [
    "Write down your solution here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "**4. Step: Compute the new Centroids**\n",
    "\n",
    "- **Centroid of Partition 1:**\n",
    "\n",
    "    - $x = \\frac{1 + 1 + 2}{3} = 4/3 \\approx 1,333$\n",
    "    - $y = \\frac{1 + 2 + 1}{3} = 4/3 \\approx 1,333$\n",
    "\n",
    "- **Centroid of Partition 2:**\n",
    "\n",
    "    - $x = \\frac{1 + 2 + 3 + 3}{4} = 2,25$\n",
    "    - $y = \\frac{4 + 3 + 2 + 4}{4} = 3,25$ \n",
    "\n",
    "- **Centroid of Partition 3:**\n",
    "\n",
    "    - $x = \\frac{4 + 4 + 4}{3} = 4$\n",
    "    - $y = \\frac{1 + 3 + 4}{3} = \\frac{8}{3} \\approx 2,667$ \n",
    "\n",
    "\n",
    "**5. Step: Compute the new Distances**\n",
    "\n",
    "- **Data Point at (1,1):**\n",
    "    - $Distance_{(1,1)\\leftrightarrow(1.33,1.33)} = \\sqrt{(1-1.33)^2+(1-1.33)^2} \\approx 0.47$\n",
    "    - $Distance_{(1,1)\\leftrightarrow(2.25,3.25)} = \\sqrt{(1-2.25)^2+(1-3.25)^2} \\approx 2.57$\n",
    "    - $Distance_{(1,1)\\leftrightarrow(4.0,2.67)} = \\sqrt{(1-4.0)^2+(1-2.67)^2} \\approx 3.43$\n",
    " \n",
    "    Nearest centroid: $(1.33,1.33)$ (Partition 1)\n",
    " \n",
    "- **Data Point at (1,2):**\n",
    "    - $Distance_{(1,2)\\leftrightarrow(1.33,1.33)} = \\sqrt{(1-1.33)^2+(2-1.33)^2} \\approx 0.75$\n",
    "    - $Distance_{(1,2)\\leftrightarrow(2.25,3.25)} = \\sqrt{(1-2.25)^2+(2-3.25)^2} \\approx 1.77$\n",
    "    - $Distance_{(1,2)\\leftrightarrow(4.0,2.67)} = \\sqrt{(1-4.0)^2+(2-2.67)^2} \\approx 3.07$\n",
    "\n",
    "    Nearest centroid: $(1.33,1.33)$ (Partition 1)\n",
    " \n",
    "- **Data Point at (1,4):**\n",
    "    - $Distance_{(1,4)\\leftrightarrow(1.33,1.33)} = \\sqrt{(1-1.33)^2+(4-1.33)^2} \\approx 2.69$\n",
    "    - $Distance_{(1,4)\\leftrightarrow(2.25,3.25)} = \\sqrt{(1-2.25)^2+(4-3.25)^2} \\approx 1.46$\n",
    "    - $Distance_{(1,4)\\leftrightarrow(4.0,2.67)} = \\sqrt{(1-4.0)^2+(4-2.67)^2} \\approx 3.28$\n",
    "\n",
    "    Nearest centroid: $(2.25,3.25)$ (Partition 2)\n",
    " \n",
    "- **Data Point at (2,1):**\n",
    "    - $Distance_{(2,1)\\leftrightarrow(1.33,1.33)} = \\sqrt{(2-1.33)^2+(1-1.33)^2} \\approx 0.75$\n",
    "    - $Distance_{(2,1)\\leftrightarrow(2.25,3.25)} = \\sqrt{(2-2.25)^2+(1-3.25)^2} \\approx 2.26$\n",
    "    - $Distance_{(2,1)\\leftrightarrow(4.0,2.67)} = \\sqrt{(2-4.0)^2+(1-2.67)^2} \\approx 2.6$\n",
    "\n",
    "    Nearest centroid: $(1.33,1.33)$ (Partition 1)\n",
    " \n",
    "- **Data Point at (2,3):**\n",
    "    - $Distance_{(2,3)\\leftrightarrow(1.33,1.33)} = \\sqrt{(2-1.33)^2+(3-1.33)^2} \\approx 1.8$\n",
    "    - $Distance_{(2,3)\\leftrightarrow(2.25,3.25)} = \\sqrt{(2-2.25)^2+(3-3.25)^2} \\approx 0.35$\n",
    "    - $Distance_{(2,3)\\leftrightarrow(4.0,2.67)} = \\sqrt{(2-4.0)^2+(3-2.67)^2} \\approx 2.03$\n",
    "\n",
    "    Nearest centroid: $(2.25,3.25)$ (Partition 2)\n",
    " \n",
    "- **Data Point at (3,2):**\n",
    "    - $Distance_{(3,2)\\leftrightarrow(1.33,1.33)} = \\sqrt{(3-1.33)^2+(2-1.33)^2} \\approx 1.8$\n",
    "    - $Distance_{(3,2)\\leftrightarrow(2.25,3.25)} = \\sqrt{(3-2.25)^2+(2-3.25)^2} \\approx 1.46$\n",
    "    - $Distance_{(3,2)\\leftrightarrow(4.0,2.67)} = \\sqrt{(3-4.0)^2+(2-2.67)^2} \\approx 1.2$\n",
    "\n",
    "    Nearest centroid: $(4.0,2.67)$ (Partition 3)\n",
    " \n",
    "- **Data Point at (3,4):**\n",
    "    - $Distance_{(3,4)\\leftrightarrow(1.33,1.33)} = \\sqrt{(3-1.33)^2+(4-1.33)^2} \\approx 3.14$\n",
    "    - $Distance_{(3,4)\\leftrightarrow(2.25,3.25)} = \\sqrt{(3-2.25)^2+(4-3.25)^2} \\approx 1.06$\n",
    "    - $Distance_{(3,4)\\leftrightarrow(4.0,2.67)} = \\sqrt{(3-4.0)^2+(4-2.67)^2} \\approx 1.67$\n",
    "\n",
    "    Nearest centroid: $(2.25,3.25)$ (Partition 2)\n",
    " \n",
    "- **Data Point at (4,1):**\n",
    "    - $Distance_{(4,1)\\leftrightarrow(1.33,1.33)} = \\sqrt{(4-1.33)^2+(1-1.33)^2} \\approx 2.69$\n",
    "    - $Distance_{(4,1)\\leftrightarrow(2.25,3.25)} = \\sqrt{(4-2.25)^2+(1-3.25)^2} \\approx 2.85$\n",
    "    - $Distance_{(4,1)\\leftrightarrow(4.0,2.67)} = \\sqrt{(4-4.0)^2+(1-2.67)^2} \\approx 1.67$\n",
    "\n",
    "    Nearest centroid: $(4.0,2.67)$ (Partition 3)\n",
    " \n",
    "- **Data Point at (4,3):**\n",
    "    - $Distance_{(4,3)\\leftrightarrow(1.33,1.33)} = \\sqrt{(4-1.33)^2+(3-1.33)^2} \\approx 3.14$\n",
    "    - $Distance_{(4,3)\\leftrightarrow(2.25,3.25)} = \\sqrt{(4-2.25)^2+(3-3.25)^2} \\approx 1.77$\n",
    "    - $Distance_{(4,3)\\leftrightarrow(4.0,2.67)} = \\sqrt{(4-4.0)^2+(3-2.67)^2} \\approx 0.33$\n",
    "\n",
    "    Nearest centroid: $(4.0,2.67)$ (Partition 3)\n",
    " \n",
    "- **Data Point at (4,4):**\n",
    "    - $Distance_{(4,4)\\leftrightarrow(1.33,1.33)} = \\sqrt{(4-1.33)^2+(4-1.33)^2} \\approx 3.77$\n",
    "    - $Distance_{(4,4)\\leftrightarrow(2.25,3.25)} = \\sqrt{(4-2.25)^2+(4-3.25)^2} \\approx 1.9$\n",
    "    - $Distance_{(4,4)\\leftrightarrow(4.0,2.67)} = \\sqrt{(4-4.0)^2+(4-2.67)^2} \\approx 1.33$\n",
    "\n",
    "    Nearest centroid: $(4.0,2.67)$ (Partition 3)\n",
    "\n",
    "\n",
    "**6. Step: Reassign the Data Points**\n",
    "\n",
    "| x | y | Old Partition | New Partition |\n",
    "|:-:|:-:|:-------------:|:-------------:|\n",
    "| 1 | 1 |       1       |       1       |\n",
    "| 1 | 2 |       1       |       1       |\n",
    "| 1 | 4 |       2       |       2       |\n",
    "| 2 | 1 |       1       |       1       |\n",
    "| 2 | 3 |       2       |       2       |\n",
    "| 3 | 2 |       2       |       3       |\n",
    "| 3 | 4 |       2       |       2       |\n",
    "| 4 | 1 |       3       |       3       |\n",
    "| 4 | 3 |       3       |       3       |\n",
    "| 4 | 4 |       3       |       3       |\n",
    "\n",
    "\n",
    "**7. Step: Compute the new Centroids**\n",
    "\n",
    "- **Centroid of Partition 1:**\n",
    "\n",
    "    - $x = \\frac{1 + 1 + 2}{3} = 4/3 \\approx 1,333$\n",
    "    - $y = \\frac{1 + 2 + 1}{3} = 4/3 \\approx 1,333$\n",
    "\n",
    "- **Centroid of Partition 2:**\n",
    "\n",
    "    - $x = \\frac{1 + 2 + 3}{3} = 2$\n",
    "    - $y = \\frac{4 + 3 + 4}{3} = 11/3 \\approx 3,667$ \n",
    "\n",
    "- **Centroid of Partition 3:**\n",
    "\n",
    "    - $x = \\frac{3 + 4 + 4 + 4}{4} = 3,75$\n",
    "    - $y = \\frac{2 + 1 + 3 + 4}{4} = 2,5$ \n",
    "\n",
    "\n",
    "**8. Step: Compute the new Distances**\n",
    "\n",
    "- **Data Point at (1,1):**\n",
    "    - $Distance_{(1,1)\\leftrightarrow(1.33,1.33)} = \\sqrt{(1-1.33)^2+(1-1.33)^2} \\approx 0.47$\n",
    "    - $Distance_{(1,1)\\leftrightarrow(2.0,3.67)} = \\sqrt{(1-2.0)^2+(1-3.67)^2} \\approx 2.85$\n",
    "    - $Distance_{(1,1)\\leftrightarrow(3.75,2.5)} = \\sqrt{(1-3.75)^2+(1-2.5)^2} \\approx 3.13$\n",
    "\n",
    "    Nearest centroid: $(1.33,1.33)$ (Partition 1)\n",
    " \n",
    "- **Data Point at (1,2):**\n",
    "    - $Distance_{(1,2)\\leftrightarrow(1.33,1.33)} = \\sqrt{(1-1.33)^2+(2-1.33)^2} \\approx 0.75$\n",
    "    - $Distance_{(1,2)\\leftrightarrow(2.0,3.67)} = \\sqrt{(1-2.0)^2+(2-3.67)^2} \\approx 1.94$\n",
    "    - $Distance_{(1,2)\\leftrightarrow(3.75,2.5)} = \\sqrt{(1-3.75)^2+(2-2.5)^2} \\approx 2.8$\n",
    "\n",
    "    Nearest centroid: $(1.33,1.33)$ (Partition 1)\n",
    " \n",
    "- **Data Point at (1,4):**\n",
    "    - $Distance_{(1,4)\\leftrightarrow(1.33,1.33)} = \\sqrt{(1-1.33)^2+(4-1.33)^2} \\approx 2.69$\n",
    "    - $Distance_{(1,4)\\leftrightarrow(2.0,3.67)} = \\sqrt{(1-2.0)^2+(4-3.67)^2} \\approx 1.05$\n",
    "    - $Distance_{(1,4)\\leftrightarrow(3.75,2.5)} = \\sqrt{(1-3.75)^2+(4-2.5)^2} \\approx 3.13$\n",
    "\n",
    "    Nearest centroid: $(2.0,3.67)$ (Partition 2)\n",
    " \n",
    "- **Data Point at (2,1):**\n",
    "    - $Distance_{(2,1)\\leftrightarrow(1.33,1.33)} = \\sqrt{(2-1.33)^2+(1-1.33)^2} \\approx 0.75$\n",
    "    - $Distance_{(2,1)\\leftrightarrow(2.0,3.67)} = \\sqrt{(2-2.0)^2+(1-3.67)^2} \\approx 2.67$\n",
    "    - $Distance_{(2,1)\\leftrightarrow(3.75,2.5)} = \\sqrt{(2-3.75)^2+(1-2.5)^2} \\approx 2.3$\n",
    "\n",
    "    Nearest centroid: $(1.33,1.33)$ (Partition 1)\n",
    " \n",
    "- **Data Point at (2,3):**\n",
    "    - $Distance_{(2,3)\\leftrightarrow(1.33,1.33)} = \\sqrt{(2-1.33)^2+(3-1.33)^2} \\approx 1.8$\n",
    "    - $Distance_{(2,3)\\leftrightarrow(2.0,3.67)} = \\sqrt{(2-2.0)^2+(3-3.67)^2} \\approx 0.67$\n",
    "    - $Distance_{(2,3)\\leftrightarrow(3.75,2.5)} = \\sqrt{(2-3.75)^2+(3-2.5)^2} \\approx 1.82$\n",
    "\n",
    "    Nearest centroid: $(2.0,3.67)$ (Partition 2)\n",
    " \n",
    "- **Data Point at (3,2):**\n",
    "    - $Distance_{(3,2)\\leftrightarrow(1.33,1.33)} = \\sqrt{(3-1.33)^2+(2-1.33)^2} \\approx 1.8$\n",
    "    - $Distance_{(3,2)\\leftrightarrow(2.0,3.67)} = \\sqrt{(3-2.0)^2+(2-3.67)^2} \\approx 1.94$\n",
    "    - $Distance_{(3,2)\\leftrightarrow(3.75,2.5)} = \\sqrt{(3-3.75)^2+(2-2.5)^2} \\approx 0.9$\n",
    "\n",
    "    Nearest centroid: $(3.75,2.5)$ (Partition 3)\n",
    " \n",
    "- **Data Point at (3,4):**\n",
    "    - $Distance_{(3,4)\\leftrightarrow(1.33,1.33)} = \\sqrt{(3-1.33)^2+(4-1.33)^2} \\approx 3.14$\n",
    "    - $Distance_{(3,4)\\leftrightarrow(2.0,3.67)} = \\sqrt{(3-2.0)^2+(4-3.67)^2} \\approx 1.05$\n",
    "    - $Distance_{(3,4)\\leftrightarrow(3.75,2.5)} = \\sqrt{(3-3.75)^2+(4-2.5)^2} \\approx 1.68$\n",
    "\n",
    "    Nearest centroid: $(2.0,3.67)$ (Partition 2)\n",
    " \n",
    "- **Data Point at (4,1):**\n",
    "    - $Distance_{(4,1)\\leftrightarrow(1.33,1.33)} = \\sqrt{(4-1.33)^2+(1-1.33)^2} \\approx 2.69$\n",
    "    - $Distance_{(4,1)\\leftrightarrow(2.0,3.67)} = \\sqrt{(4-2.0)^2+(1-3.67)^2} \\approx 3.33$\n",
    "    - $Distance_{(4,1)\\leftrightarrow(3.75,2.5)} = \\sqrt{(4-3.75)^2+(1-2.5)^2} \\approx 1.52$\n",
    "\n",
    "    Nearest centroid: $(3.75,2.5)$ (Partition 3)\n",
    " \n",
    "- **Data Point at (4,3):**\n",
    "    - $Distance_{(4,3)\\leftrightarrow(1.33,1.33)} = \\sqrt{(4-1.33)^2+(3-1.33)^2} \\approx 3.14$\n",
    "    - $Distance_{(4,3)\\leftrightarrow(2.0,3.67)} = \\sqrt{(4-2.0)^2+(3-3.67)^2} \\approx 2.11$\n",
    "    - $Distance_{(4,3)\\leftrightarrow(3.75,2.5)} = \\sqrt{(4-3.75)^2+(3-2.5)^2} \\approx 0.56$\n",
    "\n",
    "    Nearest centroid: $(3.75,2.5)$ (Partition 3)\n",
    "\n",
    "- **Data Point at (4,4):**\n",
    "    - $Distance_{(4,4)\\leftrightarrow(1.33,1.33)} = \\sqrt{(4-1.33)^2+(4-1.33)^2} \\approx 3.77$\n",
    "    - $Distance_{(4,4)\\leftrightarrow(2.0,3.67)} = \\sqrt{(4-2.0)^2+(4-3.67)^2} \\approx 2.03$\n",
    "    - $Distance_{(4,4)\\leftrightarrow(3.75,2.5)} = \\sqrt{(4-3.75)^2+(4-2.5)^2} \\approx 1.52$\n",
    "\n",
    "    Nearest centroid: $(3.75,2.5)$ (Partition 3)\n",
    "\n",
    "\n",
    "**9. Step: Reassign the Data Points**\n",
    "\n",
    "| x | y | Old Partition | New Partition |\n",
    "|:-:|:-:|:-------------:|:-------------:|\n",
    "| 1 | 1 |       1       |       1       |\n",
    "| 1 | 2 |       1       |       1       |\n",
    "| 1 | 4 |       2       |       2       |\n",
    "| 2 | 1 |       1       |       1       |\n",
    "| 2 | 3 |       2       |       2       |\n",
    "| 3 | 2 |       3       |       3       |\n",
    "| 3 | 4 |       2       |       2       |\n",
    "| 4 | 1 |       3       |       3       |\n",
    "| 4 | 3 |       3       |       3       |\n",
    "| 4 | 4 |       3       |       3       |\n",
    "\n",
    "\n",
    "**10. Step: Termination**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "#### 5.1.1.2. Implementation\n",
    "\n",
    "Manual calculation of K-Means is obviously not feasible for larger data sets. For this reason, the next step is to focus on the implementation of K-Means.\n",
    "\n",
    "Again, there are two possible routes you might go:\n",
    "\n",
    "- **Option 1:** [Implement K-Means on Your Own](#Option-1:-Implement-K-Means-on-Your-Own)\n",
    "- **Option 2:** [Step-by-step Implementation of K-Means](#Option-2:-Step-by-step-Implementation-of-K-Means)\n",
    "\n",
    "It is recommended that you first try on your own and only resort to the guided step-by-step variant if you have problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "##### Option 1: Implement K-Means on Your Own\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 2.1:**\n",
    "    \n",
    "Use your knowledge of K-means to implement a method `k_means` that can be used to cluster the `dataset` and into `k` clusters using the euclidean distance to measure the distance between two points.\n",
    "If you are in need of more code cells than provided, feel free to add more.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Implement a k_means function (Code placeholder 01/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Implement a k_means function (Code placeholder 02/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Implement a k_means function (Code placeholder 03/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Implement a k_means function (Code placeholder 04/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Implement a k_means function (Code placeholder 05/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Implement a k_means function (Code placeholder 06/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Implement a k_means function (Code placeholder 07/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Implement a k_means function (Code placeholder 08/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Implement a k_means function (Code placeholder 09/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Implement a k_means function (Code placeholder 10/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Sample k_means sceleton\n",
    "# NOTE: You are allowed to use this sceleton but don't have to\n",
    "def k_means(dataset, k):\n",
    "    # Copy the original dataset\n",
    "    dataset_copy = dataset.copy()\n",
    "\n",
    "    # Create a new empty column to save the cluster/partition affiliation (-1 is representing no cluster/partition)\n",
    "    dataset_copy[\"cluster\"] = -1\n",
    "\n",
    "    # ...\n",
    "    return dataset_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Cluster the dataset (We use k=3)\n",
    "clustered_dataset = k_means(dataset, 3)\n",
    "\n",
    "# Print a scatterplot\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.scatterplot(\n",
    "    x=clustered_dataset[\"x\"],\n",
    "    y=clustered_dataset[\"y\"],\n",
    "    hue=clustered_dataset[\"cluster\"],\n",
    "    palette=\"deep\",\n",
    "    legend=None,\n",
    ")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Sample solution => See Option 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "##### Option 2: Step-by-step Implementation of K-Means\n",
    "\n",
    "The initial step of K-means is to make an initial partition of the existing data into `k` non-empty partitions. This division can be random or according to an arbitrary scheme. It is important that the result are exactly `k` partitions, that none of these partitions is empty and that each sample is represented in exactly one of the partitions. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 2.2.1:** \n",
    "    \n",
    "Write a function `partition_dataset` that splits a `dataset` into `k` initial partitions. It doesn`t matter what kind of partitioning you decide on, as long as it complies with the rules mentioned. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Implement a function to arbitrarily partition the dataset into k parts\n",
    "def partition_dataset(dataset, k):\n",
    "    # Copy the original dataset\n",
    "    dataset_copy = dataset.copy()\n",
    "\n",
    "    # Create a new empty column to save the cluster/partition affiliation (-1 is representing no cluster/partition)\n",
    "    dataset_copy[\"cluster\"] = -1\n",
    "\n",
    "    # ...\n",
    "\n",
    "    # Return the dataset\n",
    "    return dataset_copy\n",
    "\n",
    "\n",
    "# Partition the dataset\n",
    "partitioned_dataset = partition_dataset(dataset, 3)\n",
    "\n",
    "# Print a scatterplot\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.scatterplot(\n",
    "    x=partitioned_dataset[\"x\"],\n",
    "    y=partitioned_dataset[\"y\"],\n",
    "    hue=partitioned_dataset[\"cluster\"],\n",
    "    palette=\"deep\",\n",
    ")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Implement a function to arbitrarily partition the dataset into k parts\n",
    "def partition_dataset(dataset, k):\n",
    "    # Copy the original dataset\n",
    "    dataset_copy = dataset.copy()\n",
    "\n",
    "    # Create a new empty column to save the cluster/partition affiliation (-1 is representing no cluster/partition)\n",
    "    dataset_copy[\"cluster\"] = -1\n",
    "\n",
    "    # Compute quotient and the remainder if spliting the dataset into k parts\n",
    "    quotient, remainder = divmod(dataset_copy.shape[0], k)\n",
    "\n",
    "    # And then to assign the samples to the cluster/partition\n",
    "    for i in range(0, k):\n",
    "        # Assign the cluster value\n",
    "        dataset_copy.loc[\n",
    "            i * quotient\n",
    "            + min(i, remainder) : (i + 1) * quotient\n",
    "            + min(i + 1, remainder),\n",
    "            \"cluster\",\n",
    "        ] = i\n",
    "\n",
    "    # Return the dataset\n",
    "    return dataset_copy\n",
    "\n",
    "\n",
    "# Partition the dataset\n",
    "partitioned_dataset = partition_dataset(dataset, 3)\n",
    "\n",
    "# Print a scatterplot\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.scatterplot(\n",
    "    x=partitioned_dataset[\"x\"],\n",
    "    y=partitioned_dataset[\"y\"],\n",
    "    hue=partitioned_dataset[\"cluster\"],\n",
    "    palette=\"deep\",\n",
    ")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "The next step is to calculate the centroids for each partition/cluster. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 2.2.2:**\n",
    "    \n",
    "Implement the function `compute_centroids` that computes the centroid for each of the `k` partitions. The return value should be a pandas DataFrame with the cluster identifier as an index and two columns `x` and `y` indicating the coordinates of the corresponding centroid.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Implement a function to compute the centroids for a partitioned dataset\n",
    "def compute_centroids(partitioned_dataset, k):\n",
    "    # Init a DataFrame to hold the centroids\n",
    "    centroids = pd.DataFrame(\n",
    "        [[np.nan, np.nan] for i in range(0, k)], columns=[\"x\", \"y\"]\n",
    "    )\n",
    "\n",
    "    # ...\n",
    "\n",
    "    # Return the centroids\n",
    "    return centroids\n",
    "\n",
    "\n",
    "# Compute the centroids of the intitial partitioning\n",
    "centroids = compute_centroids(partitioned_dataset, 3)\n",
    "\n",
    "# Print the centroids into the scatterplot (black)\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.scatterplot(\n",
    "    x=partitioned_dataset[\"x\"],\n",
    "    y=partitioned_dataset[\"y\"],\n",
    "    hue=partitioned_dataset[\"cluster\"],\n",
    "    palette=\"deep\",\n",
    ")\n",
    "sns.scatterplot(x=centroids[\"x\"], y=centroids[\"y\"], c=[\"black\"])\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Implement a function to compute the centroids for a partitioned dataset\n",
    "def compute_centroids(partitioned_dataset, k):\n",
    "    # Init a DataFrame to hold the centroids\n",
    "    centroids = pd.DataFrame(\n",
    "        [[np.nan, np.nan] for i in range(0, k)], columns=[\"x\", \"y\"]\n",
    "    )\n",
    "\n",
    "    # Compute the centroid of each partition\n",
    "    for i in range(0, k):\n",
    "        # Compute the mean of the x values within that single partition\n",
    "        x_mean = partitioned_dataset[partitioned_dataset[\"cluster\"] == i][\"x\"].mean()\n",
    "\n",
    "        # Compute the mean of the y values within that single partition\n",
    "        y_mean = partitioned_dataset[partitioned_dataset[\"cluster\"] == i][\"y\"].mean()\n",
    "\n",
    "        # Add the centroid of this single partition\n",
    "        centroids.loc[i, [\"x\", \"y\"]] = [x_mean, y_mean]\n",
    "\n",
    "    # Return the centroids\n",
    "    return centroids\n",
    "\n",
    "\n",
    "# Compute the centroids of the intitial partitioning\n",
    "centroids = compute_centroids(partitioned_dataset, 3)\n",
    "\n",
    "# Print the centroids into the scatterplot (black)\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.scatterplot(\n",
    "    x=partitioned_dataset[\"x\"],\n",
    "    y=partitioned_dataset[\"y\"],\n",
    "    hue=partitioned_dataset[\"cluster\"],\n",
    "    palette=\"deep\",\n",
    ")\n",
    "sns.scatterplot(x=centroids[\"x\"], y=centroids[\"y\"], c=[\"black\"])\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "To reassign points to their nearest centroid, distance measure must be defined. Here the Euclidean distance comes in handy, which we have already implemented in an earlier exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "outputs": [],
   "source": [
    "# \"Pythonic\" implementation of the euclidean distance\n",
    "def euclidean_distance(a, b):\n",
    "    return (abs(a - b) ** 2).sum() ** 0.5\n",
    "\n",
    "\n",
    "# Compute the euclidean distance for two random points a and b\n",
    "a = pd.Series([1, 1])\n",
    "b = pd.Series([2, 2])\n",
    "euclidean_distance(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "Reassignment is the next step within K-means. Samples are reassigned to the cluster/partition whose centroid is closest to themselves.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 2.2.3:**\n",
    "    \n",
    "Complete the function `reassign_samples` that reassigns samples to the cluster/partition whose centroid is closest to themselves. Return the dataset and an indictator to communicate whether at least tuple was reassigned within the function or not.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Implement a function to reassign each sample to its nearest centroid\n",
    "def reassign_samples(partitioned_dataset, centroids, k):\n",
    "    # Indicator to show whether there was at least one tuple reassigned\n",
    "    reassign_indicator = False\n",
    "\n",
    "    # Copy the original partitioned_dataset\n",
    "    dataset_copy = partitioned_dataset.copy()\n",
    "\n",
    "    # ...\n",
    "\n",
    "    return reassign_indicator, dataset_copy\n",
    "\n",
    "\n",
    "# Reassign the samples of our partitioned_dataset to their nearest centroid\n",
    "reassign_indicator, reassigned_dataset = reassign_samples(\n",
    "    partitioned_dataset, centroids, 3\n",
    ")\n",
    "\n",
    "# Output the indicator\n",
    "print(\"Was there at least one sample reassigned? - \" + str(reassign_indicator))\n",
    "\n",
    "# Print a scatterplot showing the new class assignments\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.scatterplot(\n",
    "    x=reassigned_dataset[\"x\"],\n",
    "    y=reassigned_dataset[\"y\"],\n",
    "    hue=reassigned_dataset[\"cluster\"],\n",
    "    palette=\"deep\",\n",
    ")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Implement a function to reassign each sample to its nearest centroid\n",
    "def reassign_samples(partitioned_dataset, centroids, k):\n",
    "    # Indicator to show whether there was at least one tuple reassigned\n",
    "    reassign_indicator = False\n",
    "\n",
    "    # Copy the original partitioned_dataset\n",
    "    dataset_copy = partitioned_dataset.copy()\n",
    "\n",
    "    # Check for each sample whether it has to be reassigned\n",
    "    for i in range(0, dataset_copy.shape[0]):\n",
    "        # Get the value of the the dataset for easier access\n",
    "        sample = dataset_copy.loc[i, [\"x\", \"y\"]]\n",
    "\n",
    "        # Set the current cluster id and centroid values\n",
    "        current_cluster = dataset_copy.loc[i, \"cluster\"]\n",
    "        current_centroid = centroids.loc[current_cluster]\n",
    "        current_distance = euclidean_distance(sample, current_centroid)\n",
    "\n",
    "        # Iterate through the centroids and check whether the distance is lower than the current distance\n",
    "        # NOTE: We do not skip the current centroid, as this would complicate the code and isn't a big performance problem\n",
    "        for j in range(0, k):\n",
    "            # Compute the distance\n",
    "            distance = euclidean_distance(sample, centroids.loc[j])\n",
    "\n",
    "            # If the distance is lower than the current_distance we have to reassign\n",
    "            if distance < current_distance:\n",
    "                # Set the cluster\n",
    "                dataset_copy.loc[i, \"cluster\"] = j\n",
    "                current_cluster = j\n",
    "\n",
    "                # Set the current_centroid\n",
    "                current_centroid = centroids.loc[j]\n",
    "\n",
    "                # Set the current_distance\n",
    "                current_distance = distance\n",
    "\n",
    "                # Set the reassign_indicator\n",
    "                reassign_indicator = True\n",
    "\n",
    "    return reassign_indicator, dataset_copy\n",
    "\n",
    "\n",
    "# Reassign the samples of our partitioned_dataset to their nearest centroid\n",
    "reassign_indicator, reassigned_dataset = reassign_samples(\n",
    "    partitioned_dataset, centroids, 3\n",
    ")\n",
    "\n",
    "# Output the indicator\n",
    "print(\"Was there at least one sample reassigned? - \" + str(reassign_indicator))\n",
    "\n",
    "# Print a scatterplot showing the new class assignments\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.scatterplot(\n",
    "    x=reassigned_dataset[\"x\"],\n",
    "    y=reassigned_dataset[\"y\"],\n",
    "    hue=reassigned_dataset[\"cluster\"],\n",
    "    palette=\"deep\",\n",
    ")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "If samples have been reassigned, we have to go back to calculating the centroids. If not, then the corresponding clusters have been found. \n",
    "\n",
    "This decision can should be done in a wrapper function `k_means` which summarizes the whole algorithm.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 2.2.4:**\n",
    "    \n",
    "Use the previously implemented functions in a new function `k_means` to achieve a complete implementation of the algorithm.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Implement the wrapper function k_means\n",
    "def k_means(dataset, k):\n",
    "    # Copy the original dataset\n",
    "    dataset_copy = dataset.copy()\n",
    "\n",
    "    # Create a new empty column to save the cluster/partition affiliation (-1 is representing no cluster/partition)\n",
    "    dataset_copy[\"cluster\"] = -1\n",
    "\n",
    "    # ...\n",
    "\n",
    "    # Return the clustered dataset\n",
    "    return dataset_copy\n",
    "\n",
    "\n",
    "# Cluster the dataset\n",
    "clustered_dataset = k_means(dataset, 3)\n",
    "\n",
    "# Output the corresponding scatterplot\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.scatterplot(\n",
    "    x=clustered_dataset[\"x\"],\n",
    "    y=clustered_dataset[\"y\"],\n",
    "    hue=clustered_dataset[\"cluster\"],\n",
    "    palette=\"deep\",\n",
    ")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Implement the wrapper function k_means\n",
    "def k_means(dataset, k):\n",
    "    # Partition the dataset\n",
    "    dataset = partition_dataset(dataset, k)\n",
    "\n",
    "    # Set the reassign_indicator to True (as the intial partitioning was as reassingment in itself)\n",
    "    reassign_indicator = True\n",
    "\n",
    "    # As long as there are reassingment the following two steps are repeated\n",
    "    while reassign_indicator:\n",
    "        # Compute the centroids\n",
    "        centroids = compute_centroids(dataset, k)\n",
    "\n",
    "        # Reassign each sample to the cluster of the nearest centroid\n",
    "        reassign_indicator, dataset = reassign_samples(dataset, centroids, k)\n",
    "\n",
    "    # Return the clustered dataset\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# Cluster the dataset\n",
    "clustered_dataset = k_means(dataset, 3)\n",
    "\n",
    "# Output the corresponding scatterplot\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.scatterplot(\n",
    "    x=clustered_dataset[\"x\"],\n",
    "    y=clustered_dataset[\"y\"],\n",
    "    hue=clustered_dataset[\"cluster\"],\n",
    "    palette=\"deep\",\n",
    ")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "#### 5.1.1.3. K-Means in scikit-learn\n",
    "\n",
    "It is of course not necessary to create your own implementations for K-Means if you are doing a data science task. For example, there is a good implementation in scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 3:**\n",
    "    \n",
    "Use scikit-learn's implementation of K-means to find three clusters in the `dataset`. Print the result in a diagram.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Perform scikit-learn's k-means clustering on the dataset\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Perform scikit-learn's k-means clustering on the dataset\n",
    "kmeans = KMeans(n_clusters=3, n_init=\"auto\").fit(dataset[[\"x\", \"y\"]])\n",
    "\n",
    "# Save the labels to a copy of the dataset to generate the equivalent of our clustered_dataset\n",
    "clustered_dataset_2 = dataset.copy()\n",
    "clustered_dataset_2[\"cluster\"] = kmeans.labels_\n",
    "\n",
    "# Print the result\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.scatterplot(\n",
    "    x=clustered_dataset_2[\"x\"],\n",
    "    y=clustered_dataset_2[\"y\"],\n",
    "    hue=clustered_dataset_2[\"cluster\"],\n",
    "    palette=\"deep\",\n",
    ")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "### 5.1.2. DBSCAN\n",
    "\n",
    "In addition to the partitioning methods, density-based methods were presented in the lecture. As an example of these methods, we will take a look at DBSCAN in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "#### 5.1.2.1. Basic Terms\n",
    "\n",
    "Before starting to use DBSCAN, it is useful to recall the basic concepts of density-based methods.\n",
    "\n",
    "Given is the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "outputs": [],
   "source": [
    "# Output the dataset\n",
    "fig = plt.figure(figsize=(9, 4))\n",
    "\n",
    "# As a scatterplot\n",
    "scat = fig.add_subplot(121)\n",
    "scat.scatter(x=dataset[\"x\"], y=dataset[\"y\"])\n",
    "\n",
    "# As a table\n",
    "data = fig.add_subplot(122)\n",
    "data.axis(\"off\")\n",
    "data.table(\n",
    "    cellText=dataset.values,\n",
    "    rowLabels=dataset.index,\n",
    "    bbox=[0, 0, 1, 1],\n",
    "    colLabels=dataset.columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "##### 5.1.2.1.1. Core Point\n",
    "\n",
    "A point is a core point if there are at least $MinPts$ in the neighborhood with radius $\\epsilon$ of the point.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 4:**\n",
    "    \n",
    "Given $\\epsilon = 1$ (Euclidean distance) and $MinPts = 2$, which of the following are core points in the given data set?\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "source": [
    "| Point | Is Core Point |\n",
    "|:-----:|:-------------:|\n",
    "| (1,1) |       ?       |\n",
    "| (1,4) |       ?       |\n",
    "| (2,3) |       ?       |\n",
    "| (3,4) |       ?       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "| Point | Points in Neighboorhood | Is Core Point |\n",
    "|:-----:|:-----------------------:|:-------------:|\n",
    "| (1,1) |    (1,1),(1,2),(2,1)    |      Yes      |\n",
    "| (1,4) |          (1,4)          |       No      |\n",
    "| (2,3) |          (2,3)          |       No      |\n",
    "| (3,4) |       (3,4),(4,4)       |      Yes      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "##### 5.1.2.1.2. Directly Density-Reachable\n",
    "\n",
    "A point $q$ is directly density-reachable from a point $p$ if it belongs to the neighborhood with radius $\\epsilon$ of point $p$ and if point $p$ is a core point.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 5:**\n",
    "    \n",
    "Given $\\epsilon = 1$ (Euclidean distance) and $MinPts = 2$, which of the following points are directly density-reachable from $(1,2)$?\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "source": [
    "| Point | Is Directly Density-Reachable |\n",
    "|:-----:|:-----------------------------:|\n",
    "| (2,1) |               ?               |\n",
    "| (1,1) |               ?               |\n",
    "| (2,3) |               ?               |\n",
    "| (1,4) |               ?               |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "| Point | Is Directly Density-Reachable |\n",
    "|:-----:|:-----------------------------:|\n",
    "| (2,1) |               No              |\n",
    "| (1,1) |              Yes              |\n",
    "| (2,3) |               No              |\n",
    "| (1,4) |               No              |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "##### 5.1.2.1.3. Density-Reachable\n",
    "\n",
    "A point $q$ is density-reachable from a point $p$ if there is any chain of points $p_1, . . . , p_n$\n",
    "($p_1 = p$ and $p_n = q$) such that $p_i + 1$ is directly density-reachable from $p_i$. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 6:**\n",
    "    \n",
    "Given $\\epsilon = 1$ (Euclidean distance) and $MinPts = 2$, which of the following points are density-reachable from $(1,2)$?\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "source": [
    "| Point | Is Density-Reachable |\n",
    "|:-----:|:--------------------:|\n",
    "| (2,1) |           ?          |\n",
    "| (1,1) |           ?          |\n",
    "| (2,3) |           ?          |\n",
    "| (1,4) |           ?          |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "| Point |                Chain of Points                | Is Density-Reachable |\n",
    "|:-----:|:---------------------------------------------:|:--------------------:|\n",
    "| (2,1) | (1,2) $\\rightarrow$ (1,1) $\\rightarrow$ (2,1) |          Yes         |\n",
    "| (1,1) |           (1,2) $\\rightarrow$ (1,1)           |          Yes         |\n",
    "| (2,3) |                                               |          No          |\n",
    "| (1,4) |                                               |          No          |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 7:**\n",
    "    \n",
    "Given $\\epsilon = 1$ (Euclidean distance) and $MinPts = 3$, which of the following points are density-reachable from each other?\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "**Note:**\n",
    "    \n",
    "Be careful, as $MinPts$ has been changed for the first time. \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "source": [
    "|                                         |           |           |           |           |\n",
    "|-----------------------------------------|-----------|-----------|-----------|-----------|\n",
    "| **$\\rightarrow$ q from $\\downarrow$ p** | **(3,2)** | **(3,4)** | **(4,3)** | **(4,4)** |\n",
    "|                **(3,2)**                |     -     |     ?     |     ?     |     ?     |\n",
    "|                **(3,4)**                |     ?     |     -     |     ?     |     ?     |\n",
    "|                **(4,3)**                |     ?     |     ?     |     -     |     ?     |\n",
    "|                **(4,4)**                |     ?     |     ?     |     ?     |     -     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "|                                         |           |           |           |           |\n",
    "|-----------------------------------------|-----------|-----------|-----------|-----------|\n",
    "| **$\\rightarrow$ q from $\\downarrow$ p** | **(3,2)** | **(3,4)** | **(4,3)** | **(4,4)** |\n",
    "|                **(3,2)**                |     -     |     No    |     No    |     No    |\n",
    "|                **(3,4)**                |     No    |     -     |     No    |     No    |\n",
    "|                **(4,3)**                |     No    |     No    |     -     |     No    |\n",
    "|                **(4,4)**                |     No    |    Yes    |    Yes    |     -     |\n",
    "\n",
    "(4,4) is not reachable from (3,4) and (4,3) because these two points arent core points. On the other hand, (3,4) and (4,3) are reachable from (4,4), since (4,4) is a core point. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "##### 5.1.2.1.4. Density-Connected\n",
    "\n",
    "A point $q$ and a point $p$ are density-connected if there is any point $o$ from which both $q$ and $p$ are density-reachable.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 8:**\n",
    "    \n",
    "Given $\\epsilon = 1$ (Euclidean distance) and $MinPts = 3$, which of the following points are density-connected to $(3,4)$?\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "source": [
    "| Point | Is Density-Connected |\n",
    "|:-----:|:--------------------:|\n",
    "| (1,1) |           ?          |\n",
    "| (3,2) |           ?          |\n",
    "| (4,3) |           ?          |\n",
    "| (4,4) |           ?          |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "| Point |                Chain of Points               | Is Density-Connected |\n",
    "|:-----:|:--------------------------------------------:|:--------------------:|\n",
    "| (1,1) |                                              |          No          |\n",
    "| (3,2) |                                              |          No          |\n",
    "| (4,3) | (3,4) $\\leftarrow$ (4,4) $\\rightarrow$ (4,3) |          Yes         |\n",
    "| (4,4) |           (3,4) $\\leftarrow$ (4,4)           |          Yes         |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "#### 5.1.2.2. Application by Hand\n",
    "\n",
    "With this knowledge at hand, it is quite easy to apply DBSCAN manually. \n",
    "\n",
    "Again we take a look at the familiar data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "outputs": [],
   "source": [
    "# Output the dataset\n",
    "fig = plt.figure(figsize=(9, 4))\n",
    "\n",
    "# As a scatterplot\n",
    "scat = fig.add_subplot(121)\n",
    "scat.scatter(x=dataset[\"x\"], y=dataset[\"y\"])\n",
    "\n",
    "# As a table\n",
    "data = fig.add_subplot(122)\n",
    "data.axis(\"off\")\n",
    "data.table(\n",
    "    cellText=dataset.values,\n",
    "    rowLabels=dataset.index,\n",
    "    bbox=[0, 0, 1, 1],\n",
    "    colLabels=dataset.columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 9:**\n",
    "\n",
    "Use the pseudo code known from the lecture to apply DBSCAN to this data set manually. Given are $\\epsilon = 1$ (Euclidean distance) and $MinPts = 3$. Write down all intermediate steps.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "source": [
    "Write down your solution here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "- **1. Step:** Select random point\n",
    "\n",
    "    - Select $(1,2)$\n",
    "\n",
    "- **2. Step:** Mark $(1,2)$ as visited \n",
    "\n",
    "    | x | y | Visited |\n",
    "    |:-:|:-:|:-------:|\n",
    "    | 1 | 1 |    No   |\n",
    "    | 1 | 2 |   Yes   |\n",
    "    | 1 | 4 |    No   |\n",
    "    | 2 | 1 |    No   |\n",
    "    | 2 | 3 |    No   |\n",
    "    | 3 | 2 |    No   |\n",
    "    | 3 | 4 |    No   |\n",
    "    | 4 | 1 |    No   |\n",
    "    | 4 | 3 |    No   |\n",
    "    | 4 | 4 |    No   |\n",
    "\n",
    "- **3. Step:** Check if $(1,2)$ is core point\n",
    "\n",
    "    - Is a core point (Other points in $\\epsilon$-neighborhood: (1,1))\n",
    "    \n",
    "- **4. Step:** Create a new cluster and add $(1,2)$ to the cluster\n",
    "\n",
    "    | x | y | Visited | Cluster |\n",
    "    |:-:|:-:|:-------:|:-------:|\n",
    "    | 1 | 1 |    No   |    -    |\n",
    "    | 1 | 2 |   Yes   |    0    |\n",
    "    | 1 | 4 |    No   |    -    |\n",
    "    | 2 | 1 |    No   |    -    |\n",
    "    | 2 | 3 |    No   |    -    |\n",
    "    | 3 | 2 |    No   |    -    |\n",
    "    | 3 | 4 |    No   |    -    |\n",
    "    | 4 | 1 |    No   |    -    |\n",
    "    | 4 | 3 |    No   |    -    |\n",
    "    | 4 | 4 |    No   |    -    |\n",
    "\n",
    "- **5. Step:** Add each unvisited point in the $\\epsilon$-neighborhood of $(1,2)$ to the candidate set $N$\n",
    "\n",
    "    - $N={(1,1)}$\n",
    "\n",
    "- **6. Step:** For each point in the candidate set $N$\n",
    "\n",
    "    - **6.1. Step:** For $(1,1)$\n",
    "    \n",
    "        - **6.1.1. Step:** Add $(1,1)$ to the cluster\n",
    "        \n",
    "            | x | y | Visited | Cluster |\n",
    "            |:-:|:-:|:-------:|:-------:|\n",
    "            | 1 | 1 |    No   |    0    |\n",
    "            | 1 | 2 |   Yes   |    0    |\n",
    "            | 1 | 4 |    No   |    -    |\n",
    "            | 2 | 1 |    No   |    -    |\n",
    "            | 2 | 3 |    No   |    -    |\n",
    "            | 3 | 2 |    No   |    -    |\n",
    "            | 3 | 4 |    No   |    -    |\n",
    "            | 4 | 1 |    No   |    -    |\n",
    "            | 4 | 3 |    No   |    -    |\n",
    "            | 4 | 4 |    No   |    -    |\n",
    "\n",
    "        - **6.1.2. Step:** Mark $(1,1)$ as visited\n",
    "        \n",
    "            | x | y | Visited | Cluster |\n",
    "            |:-:|:-:|:-------:|:-------:|\n",
    "            | 1 | 1 |   Yes   |    0    |\n",
    "            | 1 | 2 |   Yes   |    0    |\n",
    "            | 1 | 4 |    No   |    -    |\n",
    "            | 2 | 1 |    No   |    -    |\n",
    "            | 2 | 3 |    No   |    -    |\n",
    "            | 3 | 2 |    No   |    -    |\n",
    "            | 3 | 4 |    No   |    -    |\n",
    "            | 4 | 1 |    No   |    -    |\n",
    "            | 4 | 3 |    No   |    -    |\n",
    "            | 4 | 4 |    No   |    -    |        \n",
    "\n",
    "        - **6.1.3. Step:** Check if $(1,1)$ is core point\n",
    "        \n",
    "            - Is a core point (Other points in $\\epsilon$-neighborhood: (2,1))\n",
    "            \n",
    "        - **6.1.4. Step:** Add each unvisited point in the $\\epsilon$-neighborhood of $(1,1)$ to the candidate set $N$\n",
    "        \n",
    "            - $N={(2,1)}$\n",
    "       \n",
    "    - **6.2. Step:** For $(2,1)$\n",
    "    \n",
    "       - **6.2.1. Step:** Add $(2,1)$ to the cluster\n",
    "        \n",
    "            | x | y | Visited | Cluster |\n",
    "            |:-:|:-:|:-------:|:-------:|\n",
    "            | 1 | 1 |    No   |    0    |\n",
    "            | 1 | 2 |   Yes   |    0    |\n",
    "            | 1 | 4 |    No   |    -    |\n",
    "            | 2 | 1 |    No   |    0    |\n",
    "            | 2 | 3 |    No   |    -    |\n",
    "            | 3 | 2 |    No   |    -    |\n",
    "            | 3 | 4 |    No   |    -    |\n",
    "            | 4 | 1 |    No   |    -    |\n",
    "            | 4 | 3 |    No   |    -    |\n",
    "            | 4 | 4 |    No   |    -    |\n",
    "\n",
    "        - **6.2.2. Step:** Mark $(2,1)$ as visited\n",
    "        \n",
    "            | x | y | Visited | Cluster |\n",
    "            |:-:|:-:|:-------:|:-------:|\n",
    "            | 1 | 1 |   Yes   |    0    |\n",
    "            | 1 | 2 |   Yes   |    0    |\n",
    "            | 1 | 4 |    No   |    -    |\n",
    "            | 2 | 1 |   Yes   |    0    |\n",
    "            | 2 | 3 |    No   |    -    |\n",
    "            | 3 | 2 |    No   |    -    |\n",
    "            | 3 | 4 |    No   |    -    |\n",
    "            | 4 | 1 |    No   |    -    |\n",
    "            | 4 | 3 |    No   |    -    |\n",
    "            | 4 | 4 |    No   |    -    |        \n",
    "\n",
    "        - **6.2.3. Step:** Check if $(2,1)$ is core point\n",
    "        \n",
    "            - Is a core point (Other points in $\\epsilon$-neighborhood: (1,1))\n",
    "            \n",
    "        - **6.2.4. Step:** Add each unvisited point in the $\\epsilon$-neighborhood of $(2,1)$ to the candidate set $N$\n",
    "        \n",
    "            $N={}$\n",
    "        \n",
    "    - **6.3. Step:** No unvisited candidates in $N$ left\n",
    "    \n",
    "- **7. Step:** Select random point\n",
    "\n",
    "    - Select $(1,4)$\n",
    "\n",
    "- **8. Step:** Mark $(1,4)$ as visited \n",
    "\n",
    "    | x | y | Visited | Cluster |\n",
    "    |:-:|:-:|:-------:|:-------:|\n",
    "    | 1 | 1 |   Yes   |    0    |\n",
    "    | 1 | 2 |   Yes   |    0    |\n",
    "    | 1 | 4 |   Yes   |    -    |\n",
    "    | 2 | 1 |   Yes   |    0    |\n",
    "    | 2 | 3 |    No   |    -    |\n",
    "    | 3 | 2 |    No   |    -    |\n",
    "    | 3 | 4 |    No   |    -    |\n",
    "    | 4 | 1 |    No   |    -    |\n",
    "    | 4 | 3 |    No   |    -    |\n",
    "    | 4 | 4 |    No   |    -    |        \n",
    "\n",
    "- **9. Step:** Check if $(1,4)$ is core point\n",
    "\n",
    "    - Is not a core point \n",
    "    \n",
    "- **10. Step:** Mark $(1.4)$ as noise\n",
    "\n",
    "    | x | y | Visited | Cluster |\n",
    "    |:-:|:-:|:-------:|:-------:|\n",
    "    | 1 | 1 |   Yes   |    0    |\n",
    "    | 1 | 2 |   Yes   |    0    |\n",
    "    | 1 | 4 |   Yes   |  Noise  |\n",
    "    | 2 | 1 |   Yes   |    0    |\n",
    "    | 2 | 3 |    No   |    -    |\n",
    "    | 3 | 2 |    No   |    -    |\n",
    "    | 3 | 4 |    No   |    -    |\n",
    "    | 4 | 1 |    No   |    -    |\n",
    "    | 4 | 3 |    No   |    -    |\n",
    "    | 4 | 4 |    No   |    -    | \n",
    "        \n",
    "- **11. Step:** Select random point\n",
    "\n",
    "    - Select $(4,4)$\n",
    "\n",
    "- **12. Step:** Mark $(4,4)$ as visited \n",
    "\n",
    "    | x | y | Visited | Cluster |\n",
    "    |:-:|:-:|:-------:|:-------:|\n",
    "    | 1 | 1 |   Yes   |    0    |\n",
    "    | 1 | 2 |   Yes   |    0    |\n",
    "    | 1 | 4 |   Yes   |  Noise  |\n",
    "    | 2 | 1 |   Yes   |    0    |\n",
    "    | 2 | 3 |    No   |    -    |\n",
    "    | 3 | 2 |    No   |    -    |\n",
    "    | 3 | 4 |    No   |    -    |\n",
    "    | 4 | 1 |    No   |    -    |\n",
    "    | 4 | 3 |    No   |    -    |\n",
    "    | 4 | 4 |   Yes   |    -    | \n",
    "        \n",
    "- **13. Step:** Check if $(4,4)$ is core point\n",
    "\n",
    "    - Is a core point (Other points in $\\epsilon$-neighborhood: (3,4),(4,3))  \n",
    "    \n",
    "- **14. Step:** Create a new cluster and add $(4,4)$ to the cluster\n",
    "\n",
    "    | x | y | Visited | Cluster |\n",
    "    |:-:|:-:|:-------:|:-------:|\n",
    "    | 1 | 1 |   Yes   |    0    |\n",
    "    | 1 | 2 |   Yes   |    0    |\n",
    "    | 1 | 4 |   Yes   |  Noise  |\n",
    "    | 2 | 1 |   Yes   |    0    |\n",
    "    | 2 | 3 |    No   |    -    |\n",
    "    | 3 | 2 |    No   |    -    |\n",
    "    | 3 | 4 |    No   |    -    |\n",
    "    | 4 | 1 |    No   |    -    |\n",
    "    | 4 | 3 |    No   |    -    |\n",
    "    | 4 | 4 |   Yes   |    1    |\n",
    "\n",
    "- **15. Step:** Add each unvisited point in the $\\epsilon$-neighborhood of $(4,4)$ to the candidate set $N$\n",
    "\n",
    "    - $N={(3,4),(4,3)}$\n",
    "\n",
    "- **16. Step:** For each point in the candidate set $N$\n",
    "\n",
    "    - **16.1. Step:** For $(3,4)$\n",
    "    \n",
    "        - **16.1.1. Step:** Add $(3,4)$ to the cluster\n",
    "        \n",
    "            | x | y | Visited | Cluster |\n",
    "            |:-:|:-:|:-------:|:-------:|\n",
    "            | 1 | 1 |   Yes   |    0    |\n",
    "            | 1 | 2 |   Yes   |    0    |\n",
    "            | 1 | 4 |   Yes   |  Noise  |\n",
    "            | 2 | 1 |   Yes   |    0    |\n",
    "            | 2 | 3 |    No   |    -    |\n",
    "            | 3 | 2 |    No   |    -    |\n",
    "            | 3 | 4 |    No   |    1    |\n",
    "            | 4 | 1 |    No   |    -    |\n",
    "            | 4 | 3 |    No   |    -    |\n",
    "            | 4 | 4 |   Yes   |    1    |\n",
    "\n",
    "        - **16.1.2. Step:** Mark $(3,4)$ as visited\n",
    "        \n",
    "            | x | y | Visited | Cluster |\n",
    "            |:-:|:-:|:-------:|:-------:|\n",
    "            | 1 | 1 |   Yes   |    0    |\n",
    "            | 1 | 2 |   Yes   |    0    |\n",
    "            | 1 | 4 |   Yes   |  Noise  |\n",
    "            | 2 | 1 |   Yes   |    0    |\n",
    "            | 2 | 3 |    No   |    -    |\n",
    "            | 3 | 2 |    No   |    -    |\n",
    "            | 3 | 4 |   Yes   |    1    |\n",
    "            | 4 | 1 |    No   |    -    |\n",
    "            | 4 | 3 |    No   |    -    |\n",
    "            | 4 | 4 |   Yes   |    1    |       \n",
    "\n",
    "        - **16.1.3. Step:** Check if $(3,4)$ is core point\n",
    "        \n",
    "            - Is a core point (Other points in $\\epsilon$-neighborhood: (4,4))\n",
    "            \n",
    "        - **16.1.4. Step:** Add each unvisited point in the $\\epsilon$-neighborhood of $(3,4)$ to the candidate set $N$\n",
    "        \n",
    "            - $N={(4,3)}$\n",
    "       \n",
    "    - **16.2. Step:** For $(4,3)$\n",
    "    \n",
    "       - **16.2.1. Step:** Add $(4,3)$ to the cluster\n",
    "        \n",
    "            | x | y | Visited | Cluster |\n",
    "            |:-:|:-:|:-------:|:-------:|\n",
    "            | 1 | 1 |   Yes   |    0    |\n",
    "            | 1 | 2 |   Yes   |    0    |\n",
    "            | 1 | 4 |   Yes   |  Noise  |\n",
    "            | 2 | 1 |   Yes   |    0    |\n",
    "            | 2 | 3 |    No   |    -    |\n",
    "            | 3 | 2 |    No   |    -    |\n",
    "            | 3 | 4 |   Yes   |    1    |\n",
    "            | 4 | 1 |    No   |    -    |\n",
    "            | 4 | 3 |    No   |    1    |\n",
    "            | 4 | 4 |   Yes   |    1    |  \n",
    "\n",
    "        - **16.2.2. Step:** Mark $(4,3)$ as visited\n",
    "        \n",
    "            | x | y | Visited | Cluster |\n",
    "            |:-:|:-:|:-------:|:-------:|\n",
    "            | 1 | 1 |   Yes   |    0    |\n",
    "            | 1 | 2 |   Yes   |    0    |\n",
    "            | 1 | 4 |   Yes   |  Noise  |\n",
    "            | 2 | 1 |   Yes   |    0    |\n",
    "            | 2 | 3 |    No   |    -    |\n",
    "            | 3 | 2 |    No   |    -    |\n",
    "            | 3 | 4 |   Yes   |    1    |\n",
    "            | 4 | 1 |    No   |    -    |\n",
    "            | 4 | 3 |   Yes   |    1    |\n",
    "            | 4 | 4 |   Yes   |    1    |        \n",
    "\n",
    "        - **16.2.3. Step:** Check if $(4,3)$ is core point\n",
    "        \n",
    "            - Is a core point (Other points in $\\epsilon$-neighborhood: (4,4))\n",
    "            \n",
    "        - **16.2.4. Step:** Add each unvisited point in the $\\epsilon$-neighborhood of $(4,3)$ to the candidate set $N$\n",
    "        \n",
    "            - $N={}$\n",
    "        \n",
    "    - **16.3. Step:** No unvisited candidates in $N$ left\n",
    "       \n",
    "- **17. Step:** Select random point\n",
    "\n",
    "    - Select $(2,3)$\n",
    "\n",
    "- **18. Step:** Mark $(2,3)$ as visited \n",
    "\n",
    "    | x | y | Visited | Cluster |\n",
    "    |:-:|:-:|:-------:|:-------:|\n",
    "    | 1 | 1 |   Yes   |    0    |\n",
    "    | 1 | 2 |   Yes   |    0    |\n",
    "    | 1 | 4 |   Yes   |  Noise  |\n",
    "    | 2 | 1 |   Yes   |    0    |\n",
    "    | 2 | 3 |   Yes   |    -    |\n",
    "    | 3 | 2 |    No   |    -    |\n",
    "    | 3 | 4 |   Yes   |    1    |\n",
    "    | 4 | 1 |    No   |    -    |\n",
    "    | 4 | 3 |   Yes   |    1    |\n",
    "    | 4 | 4 |   Yes   |    1    |        \n",
    "\n",
    "- **19. Step:** Check if $(2,3)$ is core point\n",
    "\n",
    "    - Is not a core point \n",
    "    \n",
    "- **20. Step:** Mark $(2,3)$ as noise\n",
    "\n",
    "    | x | y | Visited | Cluster |\n",
    "    |:-:|:-:|:-------:|:-------:|\n",
    "    | 1 | 1 |   Yes   |    0    |\n",
    "    | 1 | 2 |   Yes   |    0    |\n",
    "    | 1 | 4 |   Yes   |  Noise  |\n",
    "    | 2 | 1 |   Yes   |    0    |\n",
    "    | 2 | 3 |   Yes   |  Noise  |\n",
    "    | 3 | 2 |    No   |    -    |\n",
    "    | 3 | 4 |   Yes   |    1    |\n",
    "    | 4 | 1 |    No   |    -    |\n",
    "    | 4 | 3 |   Yes   |    1    |\n",
    "    | 4 | 4 |   Yes   |    1    |  \n",
    "    \n",
    "- **21. Step:** Select random point\n",
    "\n",
    "    - Select $(3,2)$\n",
    "\n",
    "- **22. Step:** Mark $(3,2)$ as visited \n",
    "\n",
    "    | x | y | Visited | Cluster |\n",
    "    |:-:|:-:|:-------:|:-------:|\n",
    "    | 1 | 1 |   Yes   |    0    |\n",
    "    | 1 | 2 |   Yes   |    0    |\n",
    "    | 1 | 4 |   Yes   |  Noise  |\n",
    "    | 2 | 1 |   Yes   |    0    |\n",
    "    | 2 | 3 |   Yes   |  Noise  |\n",
    "    | 3 | 2 |   Yes   |    -    |\n",
    "    | 3 | 4 |   Yes   |    1    |\n",
    "    | 4 | 1 |    No   |    -    |\n",
    "    | 4 | 3 |   Yes   |    1    |\n",
    "    | 4 | 4 |   Yes   |    1    |        \n",
    "\n",
    "- **23. Step:** Check if $(3,2)$ is core point\n",
    "\n",
    "    - Is not a core point \n",
    "    \n",
    "- **24. Step:** Mark $(3,2)$ as noise\n",
    "\n",
    "    | x | y | Visited | Cluster |\n",
    "    |:-:|:-:|:-------:|:-------:|\n",
    "    | 1 | 1 |   Yes   |    0    |\n",
    "    | 1 | 2 |   Yes   |    0    |\n",
    "    | 1 | 4 |   Yes   |  Noise  |\n",
    "    | 2 | 1 |   Yes   |    0    |\n",
    "    | 2 | 3 |   Yes   |  Noise  |\n",
    "    | 3 | 2 |   Yes   |  Noise  |\n",
    "    | 3 | 4 |   Yes   |    1    |\n",
    "    | 4 | 1 |    No   |    -    |\n",
    "    | 4 | 3 |   Yes   |    1    |\n",
    "    | 4 | 4 |   Yes   |    1    |  \n",
    "    \n",
    "- **25. Step:** Select random point\n",
    "\n",
    "    - Select $(4,1)$\n",
    "\n",
    "- **26. Step:** Mark $(4,1)$ as visited \n",
    "\n",
    "    | x | y | Visited | Cluster |\n",
    "    |:-:|:-:|:-------:|:-------:|\n",
    "    | 1 | 1 |   Yes   |    0    |\n",
    "    | 1 | 2 |   Yes   |    0    |\n",
    "    | 1 | 4 |   Yes   |  Noise  |\n",
    "    | 2 | 1 |   Yes   |    0    |\n",
    "    | 2 | 3 |   Yes   |  Noise  |\n",
    "    | 3 | 2 |   Yes   |  Noise  |\n",
    "    | 3 | 4 |   Yes   |    1    |\n",
    "    | 4 | 1 |   Yes   |    -    |\n",
    "    | 4 | 3 |   Yes   |    1    |\n",
    "    | 4 | 4 |   Yes   |    1    |        \n",
    "\n",
    "- **27. Step:** Check if $(4,1)$ is core point\n",
    "\n",
    "    - Is not a core point \n",
    "    \n",
    "- **28. Step:** Mark $(4,1)$ as noise\n",
    "\n",
    "    | x | y | Visited | Cluster |\n",
    "    |:-:|:-:|:-------:|:-------:|\n",
    "    | 1 | 1 |   Yes   |    0    |\n",
    "    | 1 | 2 |   Yes   |    0    |\n",
    "    | 1 | 4 |   Yes   |  Noise  |\n",
    "    | 2 | 1 |   Yes   |    0    |\n",
    "    | 2 | 3 |   Yes   |  Noise  |\n",
    "    | 3 | 2 |   Yes   |  Noise  |\n",
    "    | 3 | 4 |   Yes   |    1    |\n",
    "    | 4 | 1 |   Yes   |  Noise  |\n",
    "    | 4 | 3 |   Yes   |    1    |\n",
    "    | 4 | 4 |   Yes   |    1    | \n",
    "    \n",
    "- **29. Step:** Termination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "#### 5.1.2.3. Implementation\n",
    "\n",
    "During this implementation you have two options: \n",
    "\n",
    "- **Option 1:** [Implementation of DBSCAN on your own](#Option-1:-Implementation-of-DBSCAN-on-your-own)\n",
    "- **Option 2:** [Step-by-step implementation of DBSCAN](#Option-2:-Step-by-step-implementation-of-DBSCAN)\n",
    "\n",
    "It is recommended that you first try it on your own and only resort to the guided step-by-step variant if you have problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "##### Option 1:  Implementation of DBSCAN on your own\n",
    "\n",
    "If you decided to implement DBSCAN on your own refer to the lecture for a comprehensive explanation of the method. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 10.1:**\n",
    "    \n",
    "Implement a method `dbscan` that can be used to cluster the data set `dataset` into multiple clusters. You shall use the euclidean distance to measure the distance between two points during the clustering.\n",
    "If you are in need of more code cells than provided, feel free to add more.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Implement a dbscan function (Code placeholder 01/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Implement a dbscan function (Code placeholder 02/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Implement a dbscan function (Code placeholder 03/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Implement a dbscan function (Code placeholder 04/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Implement a dbscan function (Code placeholder 05/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Implement a dbscan function (Code placeholder 06/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Implement a dbscan function (Code placeholder 07/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Implement a dbscan function (Code placeholder 08/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Implement a dbscan function (Code placeholder 09/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Implement a dbscan function (Code placeholder 10/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Sample dbscan sceleton\n",
    "# NOTE: You are allowed to use this sceleton but don't have to\n",
    "def dbscan(dataset, eps, min_pts):\n",
    "    # Copy the original dataset\n",
    "    dataset_copy = dataset.copy()\n",
    "\n",
    "    # Create a new empty column to save the cluster/partition affiliation\n",
    "    # Special codings for ...\n",
    "    # ... points that are not set yet: -1\n",
    "    # ... points that are noise: -2\n",
    "    dataset_copy[\"cluster\"] = -1\n",
    "\n",
    "    # Create a new empty column to save the visited status\n",
    "    dataset_copy[\"visited\"] = False\n",
    "\n",
    "    # ...\n",
    "\n",
    "    # Return the clustered dataset\n",
    "    return dataset_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Cluster the dataset\n",
    "# (the parameters eps=1.5 and min_pts=2 should result in three different clusters)\n",
    "clustered_dataset = dbscan(dataset, 1.5, 2)\n",
    "\n",
    "# Output the corresponding scatterplot\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.scatterplot(\n",
    "    x=clustered_dataset[\"x\"],\n",
    "    y=clustered_dataset[\"y\"],\n",
    "    hue=clustered_dataset[\"cluster\"],\n",
    "    palette=\"deep\",\n",
    ")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Sample solution => See Option 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "##### Option 2: Step-by-step implementation of DBSCAN\n",
    "\n",
    "For DBSCAN, you need not only the cluster membership as meta information, but also the status \"visited\". Before we start with the step-by-step implementation of DBSCAN, it is useful to write a small function for preparing the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "outputs": [],
   "source": [
    "# Add columns to the dataset to save the status of the dataset\n",
    "def prepare_dataset(dataset):\n",
    "    # Copy the original dataset\n",
    "    dataset_copy = dataset.copy()\n",
    "\n",
    "    # Create a new empty column to save the visited status\n",
    "    dataset_copy[\"visited\"] = False\n",
    "\n",
    "    # Create a new empty column to save the cluster/partition affiliation\n",
    "    # Special codings for ...\n",
    "    # ... points that are not set yet: -1\n",
    "    # ... points that are noise: -2\n",
    "    dataset_copy[\"cluster\"] = -1\n",
    "\n",
    "    # Return the dataset_copy\n",
    "    return dataset_copy\n",
    "\n",
    "\n",
    "# Prepare the dataset\n",
    "prepared_dataset = prepare_dataset(dataset)\n",
    "prepared_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "Besides this preparatory helper function, there are some things that it would make sense to outsource to separate functions before the actual DBSCAN implementation. \n",
    "\n",
    "First, a function is needed in DBSCAN to randomly select a single unvisited point from a prepared data set. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 10.2.1:**\n",
    "    \n",
    "Write a function `pick_random_unvisited_point` that randomly selects an unvisited point out of the `dataset` and returns it.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Pick a random point that is unvisited\n",
    "def pick_random_unvisited_point(dataset):\n",
    "    # ...\n",
    "    return None\n",
    "\n",
    "\n",
    "# Pick a random point\n",
    "random_point = pick_random_unvisited_point(prepared_dataset)\n",
    "random_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Pick a random point that is unvisited\n",
    "def pick_random_unvisited_point(dataset):\n",
    "    # Select all points that are unvisited\n",
    "    unvisited_points = dataset[dataset[\"visited\"] == False]\n",
    "\n",
    "    # If there are no unvisited points return None\n",
    "    if len(unvisited_points) < 1:\n",
    "        return None\n",
    "    else:\n",
    "        # Select one random point and return it\n",
    "        return unvisited_points.sample().iloc[0]\n",
    "\n",
    "\n",
    "# Pick a random point\n",
    "random_point = pick_random_unvisited_point(prepared_dataset)\n",
    "random_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "A second helper function that helps implementing DBSCAN is a function that returns all point within eps distance of a selected point.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 10.2.2:**\n",
    "    \n",
    "Write a function `get_all_points_within_eps_distance` that returns all points within distance of `eps` to the passed `point`. Use the euclidean distance function introduced during the K-means part of this exercise to determine the distance between two points. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Get all points within a distance of eps next to a specific point\n",
    "def get_all_points_within_eps_distance(point, dataset, eps):\n",
    "    # ...\n",
    "    return None\n",
    "\n",
    "\n",
    "# Get all points within distance of 1 regarding to the point (6,5)\n",
    "points_within_eps_distance = get_all_points_within_eps_distance(\n",
    "    pd.Series(data=[6, 5, -1, False], index=[\"x\", \"y\", \"cluster\", \"visited\"]),\n",
    "    prepared_dataset,\n",
    "    1,\n",
    ")\n",
    "points_within_eps_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Get all points within a distance of eps next to a specific point\n",
    "def get_all_points_within_eps_distance(point, dataset, eps):\n",
    "    # Select all unvisited points within eps distance\n",
    "    return dataset[\n",
    "        dataset.apply(\n",
    "            lambda a: euclidean_distance([a[\"x\"], a[\"y\"]], point[[\"x\", \"y\"]].values)\n",
    "            <= eps,\n",
    "            axis=1,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "\n",
    "# Get all points within distance of 1 regarding to the point (1,2)\n",
    "points_within_eps_distance = get_all_points_within_eps_distance(\n",
    "    pd.Series(data=[1, 2, -1, False], index=[\"x\", \"y\", \"cluster\", \"visited\"]),\n",
    "    prepared_dataset,\n",
    "    1,\n",
    ")\n",
    "points_within_eps_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "Finally, it makes sense to outsource the entire step `For each p in N that does not yet belong to a cluster` (see the pseudo code known from the lecture) to a seperate recursive function.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 10.2.3:**\n",
    "    \n",
    "Complete the function sceleton of the function `expand_cluster` below. Remember that you can use the previously defined helper functions. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# This function is used to expand a specific cluster by one point\n",
    "# If the point is a core point (at least min_pts in eps distance) by itself\n",
    "# expand_cluster is called for each neighbor.\n",
    "def expand_cluster(dataset, eps, min_pts, point, cluster_id):\n",
    "    # ...\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# This function is used to expand a specific cluster by one point\n",
    "# If the point is a core point (at least min_pts in eps distance) by itself\n",
    "# expand_cluster is called for each neighbor.\n",
    "def expand_cluster(dataset, eps, min_pts, point, cluster_id):\n",
    "    # Add the point to the cluster\n",
    "    dataset.loc[point.name, \"cluster\"] = cluster_id\n",
    "\n",
    "    # If point was not visited, we have to visit it now\n",
    "    if dataset.loc[point.name, \"visited\"] == False:\n",
    "        # Mark the point as visited\n",
    "        dataset.loc[point.name, \"visited\"] = True\n",
    "\n",
    "        # Get all points within eps distance\n",
    "        points_within_eps_distance = get_all_points_within_eps_distance(\n",
    "            point, dataset, eps\n",
    "        )\n",
    "\n",
    "        # Check if count of points is higher than min_pts => is a core point\n",
    "        # => We have to go deeper into the recursion\n",
    "        if len(points_within_eps_distance.index) >= min_pts:\n",
    "            # Iterate through the points in eps distance\n",
    "            for index, row in points_within_eps_distance.iterrows():\n",
    "                # Check whether the neighbor is already member of a cluster\n",
    "                # (Note that a point marked as noise is not part of a cluster, too)\n",
    "                if dataset.loc[index, \"cluster\"] >= 0:\n",
    "                    # Skip that point\n",
    "                    continue\n",
    "                else:\n",
    "                    # Expand the cluster with that point\n",
    "                    expand_cluster(dataset, eps, min_pts, row, cluster_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "With the help of the recursive function `expand_cluster` it is now easy to implement the function `dbscan`, which in principle takes over the remaining steps of the pseudocode and uses `expand_cluster` whenever neighboring items have to be added to the cluster.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 10.2.4:**\n",
    "    \n",
    "Complete the `dbscan`. Again it is recommended to use the previously defined functions.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Implement dbscan\n",
    "def dbscan(dataset, eps, min_pts):\n",
    "    # Prepare the dataset\n",
    "    dataset = prepare_dataset(dataset)\n",
    "\n",
    "    # ...\n",
    "\n",
    "    # Return the clustered dataset\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# Cluster the dataset\n",
    "clustered_dataset = dbscan(dataset, 1, 2)\n",
    "\n",
    "# Output the corresponding scatterplot\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.scatterplot(\n",
    "    x=clustered_dataset[\"x\"],\n",
    "    y=clustered_dataset[\"y\"],\n",
    "    hue=clustered_dataset[\"cluster\"],\n",
    "    palette=\"deep\",\n",
    ")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Implement dbscan\n",
    "def dbscan(dataset, eps, min_pts):\n",
    "    # Prepare the dataset\n",
    "    dataset = prepare_dataset(dataset)\n",
    "\n",
    "    # While there are unvisited points pick a random one\n",
    "    while len(dataset[dataset[\"visited\"] == False]) > 0:\n",
    "        # Select a random unvisited point\n",
    "        random_point = pick_random_unvisited_point(dataset)\n",
    "\n",
    "        # Mark the random point as visited\n",
    "        dataset.loc[random_point.name, \"visited\"] = True\n",
    "\n",
    "        # Get all points within eps distance\n",
    "        points_within_eps_distance = get_all_points_within_eps_distance(\n",
    "            random_point, dataset, eps\n",
    "        )\n",
    "\n",
    "        # Check if count of points is higher than min_pts => is a core point\n",
    "        if len(points_within_eps_distance.index) < min_pts:\n",
    "            # Not a core point => mark as noise\n",
    "            dataset.loc[random_point.name, \"cluster\"] = -2\n",
    "        else:\n",
    "            # Get the last used cluster id\n",
    "            last_cluster_id = dataset[\"cluster\"].max()\n",
    "\n",
    "            # Increment the id to get an new id for the new cluster\n",
    "            new_cluster_id = last_cluster_id + 1\n",
    "\n",
    "            # Add the random point to the cluster\n",
    "            dataset.loc[random_point.name, \"cluster\"] = new_cluster_id\n",
    "\n",
    "            # Iterate through the points in eps distance\n",
    "            for index, row in points_within_eps_distance.iterrows():\n",
    "                # Check whether the neighbor is already member of a cluster\n",
    "                # (Note that a point marked as noise is not part of a cluster, too)\n",
    "                if dataset.loc[index, \"cluster\"] >= 0:\n",
    "                    # Skip that point\n",
    "                    continue\n",
    "                else:\n",
    "                    # Expand the cluster with that point\n",
    "                    expand_cluster(dataset, eps, min_pts, row, new_cluster_id)\n",
    "\n",
    "    # Return the clustered dataset\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# Cluster the dataset\n",
    "clustered_dataset = dbscan(dataset, 1, 2)\n",
    "\n",
    "# Output the corresponding scatterplot\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.scatterplot(\n",
    "    x=clustered_dataset[\"x\"],\n",
    "    y=clustered_dataset[\"y\"],\n",
    "    hue=clustered_dataset[\"cluster\"],\n",
    "    palette=\"deep\",\n",
    ")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "#### 5.1.2.4. DBSCAN in scikit-learn\n",
    "\n",
    "Just as for K-means, scikit-learn also offers an extensive implementation for DBSCAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "specification"
    ]
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 11:**\n",
    "    \n",
    "Use scikit-learn's implementation of DBSCAN to find clusters in the `dataset`. Use the same parameters we used in the above in the own implementation. Print the result in a diagram.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Perform scikit-learn's DBSCAN clustering on the dataset\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Perform scikit-learn's DBSCAN clustering on the dataset\n",
    "dbscan = DBSCAN(eps=1, min_samples=2).fit(dataset[[\"x\", \"y\"]])\n",
    "\n",
    "# Save the labels to a copy of the dataset to generate the equivalent of our clustered_dataset\n",
    "clustered_dataset = dataset.copy()\n",
    "clustered_dataset[\"cluster\"] = dbscan.labels_\n",
    "\n",
    "# Print the result\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.scatterplot(\n",
    "    x=clustered_dataset[\"x\"],\n",
    "    y=clustered_dataset[\"y\"],\n",
    "    hue=clustered_dataset[\"cluster\"],\n",
    "    palette=\"deep\",\n",
    ")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
